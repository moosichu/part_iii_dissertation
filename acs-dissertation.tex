%%
%% ACS project dissertation template.
%%
%% Currently designed for printing two-sided, but if you prefer to
%% print single-sided just remove ",twoside,openright" from the
%% \documentclass[] line below.
%%
%%
%%   SMH, May 2010.


\documentclass[a4paper,12pt,twoside,openright]{report}


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Tom M. Read Cutting\xspace}
\def\authorcollege{Downing College\xspace}
\def\authoremail{tr395@cam.ac.uk}
\def\dissertationtitle{Heterogeneous type checking in multi-language CPU-GPU systems}
\def\wordcount{6461}
\def\totalloccount{13000 }
\def\compilerloccount{12000 }


\usepackage{array,color,epsfig,float,inconsolata,graphicx,hyperref,listings,parskip,setspace,tabularx,tabu,textcomp,xspace}
\graphicspath{ {images/} }

\newfloat{lstfloat}{htbp}{lop}
\floatname{lstfloat}{Listing}
\def\lstfloatautorefname{Listing} % needed for hyperref/auroref

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC)
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{acknowledgements}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
% \listoffigures
% \listoftables

\onehalfspacing

%% START OF MAIN TEXT

\chapter{Introduction}
\pagenumbering{arabic}
\setcounter{page}{1}

\label{sec:TODO}

We provide the motivation for \textit{AnnoCheck} and \textit{CUG}: outlining
the problem they solve, why this is important and why solutions have not yet
been found. \textbf{AnnoCheck} is a cross-module annotation checker for the C
and GLSL programming languages that can be used to catch common errors when
using them to control the GPU. \textbf{CUG}\footnote{This is short for
\textit{CPU-Union-GPU}, similar logic applies to the naming of the dialects.}
takes this approach to the next level, being a programming language with two
\textit{dialects} which are each designed to target a different backend. The
dialect which targets the CPU is called \textbf{CUG-C} and the language
targeting the GPU is called \textbf{CUG-G}.

\section{Terminology}

Useful terms and domain-specific jargon are briefly explained below, and are
elaborated on in Chapter \ref{chp:technical_background}.

\begin{itemize}

    \item \textbf{GPU (Graphical Processing Unit)}: A piece of hardware that
    performs computations using a massively parallel SIMT and SIMD architecture
    \cite{GPUSIMTSIMD}. The RAM directly accessed by a GPU is called \textit{VRAM}. In
    most architectures data must be explicitly transferred from the CPU's RAM
    to the GPU's VRAM through a bus\footnote{In some architectures, the GPU and
    CPU share access to a single pool of memory\cite{PS4SpecAnalysis}}.

    \item \textbf{Shader:} A \textit{shader} is \textit{any} computer
    program written for the GPU. They were originally used for shading computer
    graphics images, but the term now applies to all GPU programs\footnote{The
    original specification for the first OpenGL shading language discusses how
    this decision was made \cite{GLSL_1_10}.}

    \item \textbf{Shading language:} These are programming languages that are
    used to write shaders. These are usually distinct languages from those used
    to write programs for the CPU.

    \item \textbf{Host language/code:} Programming languages and the resulting
    code which targets the CPU. \textit{Host} will also be used as a synonym
    for the CPU.

    \item \textbf{3D graphics library:} These are libraries which provide
    appropriate APIs for interfacing with GPUs through the host, in order to
    render 3D graphics. This includes function and API calls to load and run
    shaders on the GPU, which are implemented by the drivers for GPUs. Popular
    3D graphics libraries include \textit{OpenGL} by the \textit{Khronos Group}
    and \textit{Direct3D} by Microsoft \cite{OpenGL} \cite{Direct3D}.
    \textit{Vulkan} is low-level 3D graphics (and computation) library that is
    the successor to OpenGL \cite{Vulkan}.

    \item \textbf{GLSL/HLSL:} GLSL is the shading language OpenGL uses whilst
    HLSL is the equivalent found in Direct3D. GPU vendors are often responsible
    for writing drivers which compile source-code down to GPU machine-code at
    run-time. % \footnote{TODO(Content): Exceptions!}.

    \item \textbf{SPIR-V}: An intermediate language supported by OpenGL and
    Vulkan. Graphics drivers only have to support interpreting this language
    instead of parsing a high-level language such as GLSL. The Khronos Group
    hopes that this will spur the development of many varieties of GPU-targeted
    languages, similar to how there are many languages which compile to CPU
    machine-code \cite{SPIRV}. %TODO(Rewrite)

\end{itemize}

\section{Motivation}

\label{sec:motivation}

Graphical Processing Units (GPUs) can provide significant gains in
floating-point computing power relative to CPUs due to their highly parallel
nature \cite{CPUGPUOverTime}. This has led to a growth in the use of GPUs for
general purpose computations (known as GPGPU). Whilst GPUs were originally
designed for rendering game graphics using a fixed-function pipeline, changes
in their design have now made them increasingly programmable. This was driven
by the desire of game developers to have increasingly realistic, complex and
diverse graphics in their games. Furthermore, this has allowed GPUs to be used
in a broadening domain of applications, including machine learning, scientific
computing, and bitcoin mining \cite{GPUCrypto} \cite{GPUScientificComputing}
\cite{GPUAI}. Section \ref{sec:history_gpu} provides more details on this.

%TODO(Image!): Add an image of how a GPU works/how it compares with a CPU.

Despite this growth, the traditional toolchains used to program GPUs still
suffer from many of the problems they did when originally used by graphics
programmers in the early-to-mid 2000s:

\begin{itemize}

    \item Unless using a language with C-like syntax, the layout of data
    structures must be defined separately in GPU and CPU programs, with
    erroneous behaviour if they differ (Section \ref{sec:issues_summary}).

    \item Functions in GPU programs are identified by the CPU using strings,
    with no compile-time mechanisms available to ensure that they are correct
    (Section \ref{sec:issues_summary}).

    % \item TODO(Content) find more errors which are not addressed by this paper
    % (such as texture mis-match).

\end{itemize}

A large root-cause of these problems is the fact that regardless of the API
used, the programs written for GPUs (known as \textit{shaders}) have to be
developed in a separate environment using high-level languages based on C
(Section \ref{sec:history_gpu}) \cite{TripThroughGraphicsPipeline1}. Although
data is shared between the CPU and GPU via a bus, the programmer has to
manually ensure that the data structures used to encode that data is consistent
between the programs written for the GPU and CPU.

\begin{lstfloat}
\begin{center} C$^\sharp$ \end{center}
\begin{lstlisting}[language=C]
// C# struct definition
public struct WaveParticle
{
    public Vector2 origin;
    public Vector2 velocity;
    public float amplitude;
    public float dispersionAngle;
    public int startingFrame;
}
\end{lstlisting}
\begin{center} HLSL \end{center}
\begin{lstlisting}[language=C]
//HLSL struct definition
struct WaveParticle {
    float2 origin;
    float2 velocity;
    float amplitude;
    float dispersionAngle;
    int startingFrame;
};
\end{lstlisting}
\caption{The same data structure defined separately in C$^\sharp$ and HLSL
\cite{WaveParticlesGPU}. It is worth noting that this is much less of an issue
when using C as a host language. Most shading languages are
syntactically based on C, so they are able to share code.}
\label{lst:c_sharp_hlsl_struct_comparison}
\end{lstfloat}

Listing \ref{lst:c_sharp_hlsl_struct_comparison} demonstrates a simple example
of this kind of issue, extracted from a GPU-accelerated water-wave simulator
\cite{WaveParticlesGPU}. Units of distortion on the surface of a liquid are
represented using a data structure known as a \textit{Wave Particle}
\cite{WaveParticlesOriginalPaper}. The CPU simulates an in-world physics-system
which calculates how these particles are generated. This particle data is then
transferred to the GPU which simulates their behaviour and uses them in
rendering the surface of a liquid as shown in Figure
\ref{fig:waveparticles_example}. In this system, C$^\sharp$ is the host (CPU)
language, and HLSL is the shader language that targeted the GPU\footnote{This
is a common language combination for scripting and writing shaders for the
popular Unity game engine\cite{UnityScripting} \cite{UnityShaders}.}. Even
though both languages share the same data structure, it has to separately be
defined in both languages. If these definitions do not agree with each other,
there are no in-built mechanisms to catch the errors this causes, resulting in
incorrect run-time behaviour. Section \ref{sec:api_challanges} elaborates how
further errors can occur.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{waveparticles_example}
\caption{The output of wave particles system \cite{WaveParticlesGPU}.}
\label{fig:waveparticles_example}
\end{figure}

There has been research into pushing forward the state-of-the-art in developing
code for GPUs in more programmer-friendly ways. However, as covered in Chapter
\ref{chp:related_work}, much of the research has either been domain-specific or
provided abstractions which have an unacceptable performance overhead for many
use-cases \cite{CAMPFail1}. For example, a common approach is to design a
unified language which can be compiled to a run-time that supports GPUs, as is
the case with Lime and Halide \cite{Lime2010} \cite{Halide}. However, by hiding
the details of the heterogeneous backends it targets, Lime has no facility for
allowing the programmer to control how data is transferred between various
components, something which is crucial in game development \cite{LowLevelGPU}.
Working with low-level toolchains is an odd mix of using an API and writing
code in a GPU-specific language such as GLSL or HLSL. Research has primarily
focused on hiding the API and simplifying GPU-specific elements by designing
unified languages to abstract those details. We demonstrate that alternative
approaches which improve aspects of low-level toolchains exist.

We provided the motivation for the solutions described in this paper, first by
explaining the prevalence of GPUs and how important improvements to toolchains
which target them could be. Secondly, we demonstrated the problems low-level
toolchains face using a water simulator as brief example. Finally, we provided
a brief explanation of why research has yet to tackle these problems.

\section{The Solutions}

\label{sec:solutions_introduction}

We introduce our two systems, AnnoCheck and CUG, which we present as solutions
to the problems described above. First we describe what the desired outcomes of
those solutions should be and how they should improve over the status quo. We
then introduce the solutions themselves; firstly describing the annotation
processor AnnoCheck, before explaining its limitations. This led us to develop
CUG: a programming language with two distinct dialects.

\subsection{Desired Outcome}

As we describe in Chapter \ref{chp:related_work}, systems which aim to improve
over low-level toolchains often sacrifice some control that those traditional
workflows provide: whether it be memory management, scheduling, or which
hardware sections of code eventually target. This has two benefits: improving
the user-experience by abstracting-away low-level details, and providing an
optimising compiler with the control necessary to optimise scheduling. The
issue with this approach is the fact that precise control is still important in
many domains where GPUs are used -- to the point where programmers still choose
to make the trade-off of working directly with APIs like OpenGL or Vulkan
\cite{ListOfOpenGLGames} \cite{ListOfVulkanGames}. Therefore, solutions which
aim to build and improve upon the status quo should provide all the options
that traditional toolchains offer, including exposing any underlying GPU APIs.

Although this means these solutions are limited in the abstractions that they
can provide, there are some ``easy wins'' to be made. This is demonstrated by
the example problem shown in Listing \ref{lst:c_sharp_hlsl_struct_comparison}
and elaborated on in Section \ref{sec:api_challanges}. Some bugs introduced due
to errors in using a GPU API can be prevented by compile-time checks. That is,
instead of trying to unify code that is written for the CPU and GPU under a
single language or system which is designed to generate API calls for the
programmer, we can use compile-time checking \textit{between} CPU and GPU
languages in order to catch errors which would otherwise be left undetected.

In conclusion, any solution that aims to improve upon current programming
models should deliver the benefits described above without sacrificing anything
low-level toolchains provide. This can be done by targeting specific classes of
errors as described in Section \ref{sec:api_challanges}. We can do this with
two techniques: compile-time cross-language checks and the processing of
annotations to check the validity of raw API calls.

\subsection{What was done}

\label{sec:what_was_done}

We created two prototype systems for checking programs across language
boundaries in CPU-GPU systems. Both demonstrate a different approach in
implementing compile-time cross-language checks and checking the validity of
raw API calls for graphics programming. We chose to target the Vulkan API to
demonstrate that these ideas can work at the very lowest-level. However, the
ideas are also applicable to other APIs such as OpenGL, or Direct3D.

We first developed \textit{AnnoCheck}, a pre-processor for C and GLSL that
operates on annotated sections of code. The goal here was to demonstrate how an
existing pair of languages with similar type systems could be extended in order
to have error-checking on raw API calls. Furthermore, as C and GLSL are a
common language pairing for graphics programming, a lot of existing code could
stand to benefit from these techniques \cite{ListOfOpenGLGames}. We chose C and
GLSL as they share enough similar \textit{syntactic} properties to already
allow the programmer to share some code between them (such as struct
definitions). Although this approach has the benefit of being able to
\textit{plug-in} to existing C and GLSL code, it does have some limitations.
Firstly, the sharing of code is limited to a syntactic happenstance without
guarantees, which could result in errors (Section \ref{sec:api_challanges}).
Secondly, C's type system has limitations compared with many modern languages.
As we discuss in Chapter \ref{chp:conclusion_and_further_work}, there are many
opportunities presented by sharing code \textit{semantically} instead of just
\textit{syntactically}.

% TODO(Image!): include diagram of all the wokflows?

This led us to develop the \textit{CUG} compiler, which can compile two
language \textit{dialects} called CUG-C and CUG-G. The first goal was to
demonstrate the power that the semantic sharing of code could provide in
solving the problems we describe in Section \ref{sec:api_challanges}, as these
two dialects share the same compiler. The second goal was to show how existing
high-level languages could be extended with a shader-language. This would be
suitable for a language such as C$^\sharp$, which has a strong type system, but
is compromised and arguably \textit{less safe} than C when using shaders, as it
cannot share any code with them as shown in Listing
\ref{lst:c_sharp_hlsl_struct_comparison}. Due to resource limitations, we
designed CUG-C and CUG-G from scratch with the minimum subset of features
required in order to demonstrate that this is possible, instead of extending an
existing full-featured language such as $C^\sharp$.

One thing to note is that our goal was not to write a comprehensive set of
tools which could be used to catch all errors of this nature at compile-time.
We instead hope to show some ideas which could be used to catch various kinds
of errors, by demonstrating implementations of two prototype systems which have
been designed to capture a small subset of them. Although limited, both
projects came to a total of over 13,000 lines of code, excluding whitespace,
comments, or any example programs that we use to test these two systems.

\subsection{AnnoCheck}

AnnoCheck is a command-line program that takes annotated code written in C and
GLSL as input. An example annotation and the code that is generated is shown in
Listings \ref{lst:annotation_example_input} and
\ref{lst:annotation_example_output}. These are small snippets of the larger
program used in our Evaluation (Chapter \ref{chp:evluation}), adapted from an
example program written by Neil Henning \cite{VulkanComputeExampleSource}
\cite{VulkanComputeExampleBlog}.

\begin{lstfloat}
\begin{center}
Annotated C\footnote{We used designated initialisers in C to make it easer to
read the code \cite{DesignatedInitC}.}
\end{center}
\begin{lstlisting}[language=C]
VkComputePipelineCreateInfo compute_pipeline_create_info = {
    .sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
    // The @create_verification command is processed by
    // AnnoCheck and converted into C.
    .stage = @create_verification(
        struct: VkComputePipelineCreateInfo,
        // "verification_1" is the name of the annotation
        name: "verification_1",
        data: {
            .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
            .stage = VK_SHADER_STAGE_COMPUTE_BIT,
            .module = shader_module,
            // the struct references the main function below
            .pName = "main"
        }
    ),
    .layout = pipeline_layout
};
VkPipeline pipeline;
vkCreateComputePipelines(
    vulkan_device, 0, 1, &compute_pipeline_create_info,
    0, &pipeline
);
\end{lstlisting}
\begin{center} Annotated GLSL \end{center}
\begin{lstlisting}[language=C]
// The shader is verified against "verification_1"
@verify(from: "verification_1", function:
void main() {
    output_buffer.values[gl_GlobalInvocationID.x] = input_buffer.values[gl_GlobalInvocationID.x];
})
\end{lstlisting}
\caption{Annotated C and GLSL that can be processed by AnnoCheck. The output
that AnnoCheck produces for these snippets is shown in
Listing \ref{lst:annotation_example_output}. The full example can be found on
the project GitHub repository \cite{ProjectSource}.}
\label{lst:annotation_example_input}
\end{lstfloat}

As we will describe, Listing \ref{lst:annotation_example_input} shows an
example of an API call that can result in an error that could be checked-for at
compile-time. Here, the host code makes the \texttt{vkCreateComputePipelines}
API call in order to create a compute pipeline\footnote{This is just an API
call that needs to be made in order to run a non-graphics (compute) shader on
the GPU \cite{vkCreateComputePipelines}.} \cite{vkCreateComputePipelines}. An
instance of the \texttt{VkComputePipelineCreateInfo} struct containing a
\texttt{VkPipelineShaderStageCreateInfo} struct is passed to that API call,
which ultimately specifies which function in the shader to use within the
compute pipeline \cite{VkComputePipelineCreateInfo}
\cite{VkPipelineShaderStageCreateInfo}. Annotations are used to label the
creation of the \texttt{VkPipelineShaderStageCreateInfo} structure on the host
and the \texttt{main} function within the shader using the
\texttt{@create\_verification} and \texttt{@verify} commands respectively. The
annotation itself is given a name, \texttt{"verification\_1"}, which the
annotated C and GLSL reference. AnnoCheck takes annotated code as input and
produces the output seen in Listing \ref{lst:annotation_example_output}.

\begin{lstfloat}
\begin{center} Output C \end{center}
\begin{lstlisting}[language=C]
VkComputePipelineCreateInfo compute_pipeline_create_info = {
    .sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
    .stage = {
        .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
        .stage = VK_SHADER_STAGE_COMPUTE_BIT,
        .module = shader_module,
        .pName = "main",
    },
    .layout = pipeline_layout,
};
VkPipeline pipeline;
vkCreateComputePipelines(
    vulkan_device, 0, 1, &compute_pipeline_create_info,
    0, &pipeline
);
\end{lstlisting}
\begin{center} Output GLSL \end{center}
\begin{lstlisting}[language=C]
void main()
{
    output_buffer.values[gl_GlobalInvocationID.x] = input_buffer.values[gl_GlobalInvocationID.x];
}
\end{lstlisting}
\caption{The output generated from Listing \ref{lst:annotation_example_input}
by AnnoCheck. The full example can be found on the project GitHub repository
\cite{ProjectSource}.}
\label{lst:annotation_example_output}
\end{lstfloat}

The important key feature this example provides is the compile-time checking of
the function name -- ensuring that \texttt{main} cannot be renamed in the host
or shader without being consistently renamed in the other. If we deliberately
introduced such an error was into raw C and GLSL, the resulting behaviour would
be a runtime crash. However, not all such inconsistencies result in runtime
errors, others can simply result in incorrect or undefined runtime results.

Listing \ref{lst:annotation_example_input} demonstrates how annotations can
prevent programmers from compiling code where the names of shaders differ
between C and GLSL, informing them of the runtime error that this would cause.
The flexibility of AnnoCheck is that the programmer can remove the annotations
if they desire, especially when using complex runtime features. However,
AnnoCheck can still help ensure that an initial implementation is correct.
Furthermore, Section \ref{sec:design_annotation_processor} covers design
decisions that were made with typical shader workflows in mind such that
annotations can be kept for most use-cases.

\subsection{CUG}

CUG consists of two \textit{separate} but \textit{semantically related}
languages called \textit{CUG-C} and \textit{CUG-G}, each designed to target
different architectures. However, due to them being semantically related, we
refer to them as \textbf{dialects}. The first dialect, \textit{CUG-C}, is
designed to be compiled for the CPU. The second dialect, \textit{CUG-G} is
similarly designed to target GPUs.

We demonstrate a prototype system that allows programmers to write host-code
and shaders in programming languages that have modern features, without
sacrificing the low-level control that C and GLSL provide. We additionally
demonstrate the power that semantically sharing code can provide, compared with
the syntactic sharing of code that typically happens between C and GLSL.
Similar to how different natural-language dialects have mutually-intelligible
subsets, CUG-C and CUG-G have a mutually intelligible subset called CUG-min
that allows them to share code \textit{modules} (files).

% TODO(Task): Read https://www.khronos.org/registry/spir-v/specs/1.0/SPIRV.pdf

\begin{lstfloat}
\begin{center} CUG-C \end{center}
\begin{lstlisting}[language=C]
let shader_interface :Shader_Interface = @define_shader_interface(name="main");
let compute_pipeline_create_info: [] C::VkComputePipelineCreateInfo = [{
    sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
    pNext = null,
    flags = 0,
    stage = get_VkPipelineShaderStageCreateInfo(
        shader_interface=shader_interface
    ),
    layout = pipeline_layout,
    basePipelineHandle = 0,
    basePipelineIndex = 0
}];
var pipeline : C::VkPipeline;
C::vkCreateComputePipelines(
    device=vulkan_device,
    pipelineCache=0, createInfoCount=length(compute_pipeline_create_info),
    pCreateInfos=get_c_ptr_from_array(compute_pipeline_create_info),
    pAllocator=null,
    pPipelines=&pipeline
);
\end{lstlisting}
\begin{center} CUG-G \end{center}
\begin{lstlisting}[language=C]
let main() {
    output_buffer.values[gl_GlobalInvocationID.x] =
        input_buffer.values[gl_GlobalInvocationID.x];
}
\end{lstlisting}
\caption{Code written in CUG-C and CUG-G that has the same functionality as
Listing \ref{lst:annotation_example_input}. The full example can be found on
the project GitHub repository \cite{ProjectSource}. The Syntax is given in
\ref{sec:language_syntax}.}
\label{lst:language_example}
\end{lstfloat}

Listing \ref{lst:language_example} shows a snippet of code with the same
functionality as the annotation example shown in Listing
\ref{lst:annotation_example_input}. As can be seen, CUG-C has an in-built
directive system similar to the annotation system we created for C and GLSL.
This is used to tell the CUG compiler about the existence of a shader interface
with the name ``main''. The compiler can then check for conformance of that
interface when compiling CUG-G. We are not advocating for any particular
features of these dialects, but rather demonstrate some of the benefits a
multi-dialect system can provide. We also explore the opportunities such a
system presents in Chapter \ref{chp:conclusion_and_further_work}.

The syntax, semantics and particular features of these languages are provided
in-depth in Section \ref{sec:design_languages}. Due to the verbose nature of
using GPU APIs.

\section{Summary}

We have presented AnnoCheck and CUG, giving the motivation their creation. We
have explained that despite the existence of many techniques which
abstract-away GPU APIs, therefore simplifying heterogeneous programming,
traditional toolchains will still be used in many contexts for the forseeable
future. However, this does not mean that those traditional toolchains cannot
themselves be improved. Our first attempt, AnnoCheck, is designed to allow
programmers to annotate C and GLSL code in order to provide limited
cross-language checking. However, due to limitations with this approach, we
developed CUG, a multi-dialect programming language that solves some of the
problems we experienced with AnnoCheck. However, both systems have merits, and we
demonstrated some examples where they can help prevent common errors when using
GPU APIs.

\chapter{Technical Background}

\label{chp:technical_background}

We summarise the relevant history of graphics hardware and how it developed
over time to become useful in many fields beyond real-time rendering in video
games. Following that, the evolution of graphics APIs is provided, to give both
the context for the problem this paper aims to tackle and the underlying
technology the solutions depend upon. We explain how the complexities of
competing programming models for GPU programming, and therefore how the lack of
an ``hourglass'' ecosystem has limited the development of GPU-targeted
languages. Finally, the difficulties and issues with programming for GPUs are
summarised from the contents of this chapter.

\section{A (brief) History of GPU computing}

\label{sec:history_gpu}

Graphics Processing Units (GPUs) were originally fixed-function hardware
accelerators for 3D rendering aimed at hobbyist gamers who wanted to play games
with complex graphics \cite{GLQuake}. Due to rapid developments and
competition, the scope and capabilities of graphics cards has expanded such
that they are the highly-parallel general computation machines we find them to
be today. However, the developments GPUs experienced were not pre-planned.
Despite their current general-purpose nature, the terminology surrounding
graphics cards has its foundation in graphics and is disconnected from
programming language norms. Furthermore, standards around using GPUs and
heterogeneous hardware are still solidifying, with many fragmented communities
and confusion around the future roadmap of GPU APIs \cite{VulkanOpenCLMerge}
\cite{VulkanOpenCLNotMerge}.

This section summarises relevant milestones related to the history of
heterogeneous computing in order to help the reader understand why the field is
in a fragmented state that has hindered the development of new shading
languages. Furthermore, by giving context to development of the terms and
technologies used by both of the systems we describe, it provides the relevant
background needed to understand AnnoCheck and CUG.

\begin{itemize}

    \item 1992 \textbf{OpenGL 1.0} released by Silicon Graphics and derived
    from the proprietary ``IrisGL''. Created as an open-standard API for
    interacting with graphics hardware on 3D graphics workstations. The API
    allowed users to issue basic commands in order to set-up 3D scenes, apply
    basic fixed-function lighting, and then render the scenes
    \cite{OpenGL_1_0}. The OpenGL specification is now controlled by the
    \textbf{Khronos Group} \cite{OpenGL} \cite{OpenGLToKhronos}.

    \item 1996 \textbf{Direct3D 2.0} released by Microsoft. Although at this
    point API was designed as an abstraction for a software renderer, it
    eventually developed into an API for interfacing with graphics cards
    \cite{JohnCarmackPlanDirect3DvsOpenGl}.

    \item 1999 \textbf{NVIDIA GeForce 256} released. The first video card to be
    marketed as a \textbf{GPU}. It was the first consumer-PC graphics hardware
    to accelerate ``transform and lighting'' operations, allowing them to be
    offloaded from the CPU. The ``transform and lighting'' component of GPUs
    prefigured what would eventually run shaders \cite{GeForce256}.

    \item 2000 \textbf{The Khronos Group} was founded to provide a formal body
    for open standards in 3D graphics. Reflecting the increasing flexibility of
    graphics cards over time, they have come to additionally provide standards
    in virtual and augmented reality, heterogeneous computing, computer vision,
    parallel computing and neural networks \cite{KhronosGroupAbout}.

    \item 2001 \textbf{GPGPU}, \textit{general purpose computations on GPUs},
    are demonstrated by Larson and McAllister. They perform fast matrix
    multiplications by encoding matrices as the inputs and outputs of the
    graphics pipeline to offload calculations to the GPU \cite{MatrixGPU}.
    Subsequent papers then show how GPUs can outperform CPUs for many
    operations desirable in scientific computing \cite{CUDAtoOpenCL}
    \cite{Kruger03linearalgebra} \cite{LUGPU} \cite{SparsematrixGPU}.

    \item 2003 \textbf{OpenGL ES}, released by the Khronos Group for embedded
    systems \cite{OpenGLESRelease}. It is currently the most widely deployed 3D
    graphics API in history, being popular on mobile platforms such as Google's
    Android operating system \cite{OpenGLES}.

    \item 2004 \textbf{GLSL (OpenGL Shading Language} introduced into the
    \textbf{OpenGL 2.0} specification \cite{GLSL_1_10}. It was created to tame
    the complexity and proliferation of custom OpenGL extensions with assembly
    languages that customised parts of the fixed-function pipeline. This
    formally replaced parts of the graphics pipeline with user-programmable
    stages which were defined using a hardware-independent high-level language.
    GLSL at this point was defined as \textit{two} closely-related shading
    languages for different parts of the pipeline: the vertex processor (for
    transforming vertices) and the fragment processor (for operating on
    individual pixels in the final image). GPU vendors are responsible for
    including their own GLSL compilers in their hardware drivers
    \cite{TripThroughGraphicsPipeline1}.

    \item 2005 \textbf{Unified Shader Architecture} introduced in ATI's
    \textbf{Xenos GPU}, released as part of the Xbox 360. The ``vertex'' and
    ``pixel'' segments of the GPU pipeline are unified into a single component
    that can run either of these. This brought GPUs away from being direct
    fixed-function hardware implementations of the graphics pipeline
    represented by OpenGL and closer to being general-purpose computation
    machines \cite{XenosDemystified}. All GPUs would soon adopt this
    architecture \cite{HistoryOfTheGPU}.

    \item 2006 \textbf{CUDA} (Compute Unified Device Architecture) introduced
    by NVIDIA as a proprietary parallel computation platform and API. This
    allowed programmers to exploit the GPGPU capabilities of graphics hardware
    directly, without having to encode data as the input and output of the
    OpenGL pipeline. This made GPU computing more efficient and accessible
    \cite{AboutCUDA}. \textbf{OpenCL} is a similar open platform created by
    Apple and now maintained by the Khronos Group \cite{OpenCL}.

    \item 2015 \textbf{SPIR-V} shading language released alongside
    \textbf{OpenCL 2.1} \cite{SPIRVLaunch}. Unlike the high-level
    \textit{OpenCL C} and \textit{GLSL} shading languages which drivers need to
    compile themselves, this is an intermediate language based on \textit{LLVM
    IR} which compilers for any language can target \cite{LLVMIR} \cite{SPIRV}.
    SPIR-V support was then added to \textbf{OpenGL 4.6} and supported by
    Vulkan at launch, unifying the shading languages of Khronos' APIs
    \cite{SPIRVOpenGL}.

    \item 2016 \textbf{Vulkan} released by the Khronos Group. A low-level GPU
    API that aims to better represent how modern graphics cards are designed.
    This differs from OpenGL, whose abstraction of a traditional graphics
    pipeline no longer represents the unified nature of GPUs
    \cite{VulkanAnnouncement}. Unlike OpenGL and OpenGL ES, Vulkan is the same
    on desktop, mobile and embedded systems \cite{Vulkan}.

\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{unity_shader_madness}
\caption{The current state of the Unity game engine shader pipeline
\cite{UnityShaderPipeline}. The complexity comes from the fragmented nature
of GPU APIs.}
\label{fig:unity_shader_madness}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{unity_shader_sanity}
\caption{This is what the Unity shader pipeline shown in Figure
\ref{fig:unity_shader_madness} could look like if SPIR-V becomes the standard
intermediate representation for shader languages \cite{UnityShaderPipeline}.}
\label{fig:unity_shader_sanity}
\end{figure}

Both the capabilities of GPUs and their related APIs have massively expanded
since they were introduced, allowing GPUs to be used in increasingly general
domains (Section \ref{sec:motivation}). Unfortunately, as a result of a complex
history, there are many different APIs for different use-cases of the same
hardware (eg. OpenGL vs OpenCL). Furthermore, many of these use-cases have
widely-used proprietary alternatives such as CUDA, Direct3D,
Metal\footnote{Apple's proprietary API.} and even proprietary game console APIs
\cite{CUDA} \cite{Metal} \cite{Direct3D} \cite{PS4PortCrew} (full comparison in
Appendix \ref{sec:api_options}). This makes programming for GPUs in a portable
manner extremely complex. This is shown in Figure
\ref{fig:unity_shader_madness}, which displays how the popular Unity game
engine targets many platforms \cite{UnityShaderPipeline}.

However, with the release of SPIR-V, aspects of the various Khronos Standards
(OpenCL, OpenGL and Vulkan) are converging. Additionally, despite a foundation
in graphics, the compute capabilities of Vulkan are expanding such that OpenCL
could eventually be merged into the API \cite{VulkanOpenCLMerge}. Furthermore,
the low-level nature of new graphics and compute APIs such a Vulkan, Metal and
Direct3D 12 have allowed portability initiatives to bring implementations of
those APIs as light shims above the others \cite{VulkanPortabilityInitiative}
\cite{VulkanPortabilityInitiativeAnnouncement}. Figure
\ref{fig:unity_shader_sanity} shows how the Unity game engine's toolchain could
be simplified using SPIR-V as a backend \cite{UnityShaderPipeline}. This is
much closer to the ``hourglass'' model that CPUs provide, and will hopefully
spur on the development of many new shading languages.

\section{The Challenges with the APIs}

\label{sec:api_challanges}

% TODO(Content) mention how Vulkan is merging the OpenGL, OpenCL and OpenGL ES.

% TODO(Helpful): Good comparison of mess vs potential future (Unity Pipeline).
% http://www.g-truc.net/doc/2015%20-%20EuroLLVM%20-%20SPIR-V.pdf
% can also be shown in conclusion.

Due to the complex development history of GPU APIs such as OpenGL (Section
\ref{sec:history_gpu}), they have naturally evolved various issues, mainly as
they reflect how GPUs have \textit{historically} operated
\cite{VulkanAnnouncement}. However, this situation has recently improved with
the creation of the Vulkan API. This section does not enumerate all of the
issues graphics APIs have, but instead will briefly describe the workflow and
toolchains of using a GPU API, and then enumerate the challenges our systems
aim to ease.

\subsection{An overview of a typical GPU API}

\label{sec:graphics_api_overview}

A GPU API typically consists of two components: the API itself and a ``shader''
language that is used to write programs that run on the GPU itself. The API
will typically come in the form of a C library, with functions that the user
can call in order to direct an abstracted model of the GPU to perform specific
operations. Some of those API calls enable the user to load their shaders onto
the GPU, transfer data to the GPU, and then execute the shaders on that data.

For graphics, the full set of operations needed in order to render an image is
called the \textit{graphics pipeline} \cite{TripThroughGraphicsPipeline1}.
Although there were originally two stages, modern graphics APIs now expose up
to seven shading stages \cite{TripThroughGraphicsPipeline3}:

\begin{itemize}

    \item \textbf{VS (Vertex Shader)}: Transform vertices.

    \item \textbf{HS (Hull Shader)}: Accept patch primitives and modify patch
    control points.

    \item \textbf{DS (Domain Shader)}: Take control points from HS and convert
    them into vertices.

    \item \textbf{GS (Geometry Shader)}: Take primitives as input and generate
    new primitives from them.

    \item \textbf{PS (Pixel Shader)}: Get interpolated primitive data for each
    pixel, and output pixel color.

    \item \textbf{CS (Compute Shader)}: Its own, separate pipeline. Takes
    buffers as input and write to buffers as output. This is what is used for
    general purpose computionans (GPGPU). OpenCL and CUDA only provide APIs for
    controlling this part of the pipeline.

\end{itemize}

\begin{figure}[h]
\centering
\def\svgwidth{\linewidth}
\input{images/graphics_pipeline_stages.pdf_tex}
\caption{Different graphics pipeline configurations. Each row represents a
possible configuration of the graphics pipeline
\cite{TripThroughGraphicsPipeline3}.}
\label{fig:graphics_pipeline_stages}
\end{figure}

Figure \ref{fig:graphics_pipeline_stages} shows how these stages fit into the
overall graphics pipeline, in addition to showing different configurations of
the pipeline itself. Pipeline 1 shows how the graphics pipeline previously
operated, with only vertex and pixel shading stages. Pipeline 2 shows how the
geometry shader was added, and pipeline 3 shows the addition of the hull and
domain shaders. Pipeline 4 represents the (relatively simple) compute shading
pipeline.

Although conceptually simple, controlling the graphics pipeline is complex. As
we discuss in Chapter \ref{chp:implementation}, we focus on targeting the
compute shading stage of the pipeline through the use of the Vulkan API. As
Vulkan operates at a lower level than OpenGL and OpenCL, the API is incredibly
verbose. As we cover in Chapter \ref{chp:evaluation}, the API calls necessary
to run a simple compute shader is over 700 lines long \cite{ProjectSource}!
However, this verbosity is a feature and not a bug\footnote{We discuss the
tradeoffs this decision makes in Chapter
\ref{chp:conclusion_and_further_work}\cite{VulkanAnnouncement}.}.

\subsection{The challenges with shading languages}

\label{sec:shading_langauge_challenges}

Historically, most, if not all, shader languages have been heavily based on the
C-programming language (Appendix \ref{sec:api_options}). Furthermore, these
languages have historically been compiled by the \textit{drivers} for GPUs
\cite{TripThroughGraphicsPipeline1}. This has had a few benefits and drawbacks:

Benefits include:

\begin{itemize}

    \item Writing shaders (eg. in GLSL) is relatively straightforward if you
    are familiar with a C-like language.

    \item If C or a similar-enough language is the host language, some code can
    be shared between shaders and host code.

    \item Having a standardised high-level language helps ensure that the same
    shaders will run on hardware from a variety of different vendors.

    \item Since competing languages (eg. GLSL/HLSL) are all based on C, porting
    code from one shader language to another can even be done by simply
    performing ``find and replace'' operations \cite{PS4PortCrew}.

\end{itemize}

Drawbacks include:

\begin{itemize}

    \item High-level language specifications can be ambiguous, which means
    drivers can implement the same standard in incompatible ways
    \cite{NVIDIAInternshipLessons}.

    \item The \textit{driver} for a piece of hardware must include an entire
    compiler for a high-level language.

    \item GPU drivers are proprietary and can have bugs where semantically
    equivalent programs have different outputs (Figure \ref{fig:glfuzz})
    \cite{GLFuzz}.

    \item Shaders themselves must be tokenised, parsed, type-checked, compiled
    and optimised at run-time \cite{TripThroughGraphicsPipeline1}.

    \item If the host-language has enough syntactic differences from the shader
    language, data-structures must be defined in both languages (Listing
    \ref{lst:c_sharp_hlsl_struct_comparison}). Furthermore, there are no
    built-in mechanisms to ensure these definitions are consistent -- even at
    run-time.

    \item The C type system is limited compared with more modern programming
    languages.

    \item C and shading languages do have subtle differences. For example the
    \textbf{\texttt{int}} keyword in GLSL specifically defines a 32-bit two's
    complement integer, compared with C, where an \texttt{int} must have at
    least 16 bits and can use various encodings \cite{FundementalTypes}.
    Additionally, the placement of the \texttt{const} keyword varies in subtly
    different ways \cite{FundementalTypesGLSL}. Finally, shading languages
    natively support intrinsic types such as vectors, which many CPU languages
    do not. Therefore code sharing does not provide guarantees, and may still
    be cumbersome.

    \item GLSL does not support \texttt{\#include} directives, so code must be
    shared using a custom solution \cite{NoIncludeGLSL}.

    \item The CPU still has to refer to many identifiers within a shader using
    strings at runtime. Therefore renaming identifiers in shaders requires
    programmers to manually identify any relevant strings within their
    application.

\end{itemize}

\begin{figure}[h]
\begin{center}
GLFuzz Bug
\end{center}
\centering
\includegraphics[width=0.8\linewidth]{glfuzz}
\caption{An automated testing framework (GLFuzz) found many bugs in graphics drivers,
which resulted in errors like these. Here, a simple shader was broken by
injecting dead flow-control \cite{GLFuzz}.}
\label{fig:glfuzz}
\end{figure}

As we discussed in Section (\ref{sec:history_gpu}), high-level shading
languages such as GLSL are being phased-out in favour of lower-level
\textit{intermediate languages} such as SPIR-V \cite{SPIRV}. Therefore, modern
toolchains allow the programmer to pre-compile GLSL to SPIR-V. We discuss the
developments this has enabled in Chapter \ref{chp:related_work}.

Even with this development, GLSL is still the language of choice for graphics
APIs which use SPIR-V, leaving many presented problems unsolved.

\subsection{Issues Summary}

\label{sec:issues_summary}

We enumerate the two specific issues that AnnoCheck and CUG each solve.
Although there is overlap in which problems each system tackles, they differ in
their approaches. Concrete examples of these are evaluated in Chapter
\ref{chp:evaluation}.

\begin{itemize}

    \item \textbf{Referring to Identifiers with Strings}: The CPU refers to
    many identifiers within shaders using strings. The correctness of this
    cannot be checked by a compiler, which makes refactoring code difficult;
    especially as mis-matches result in programs crashing at
    run-time\footnote{On an Ubuntu 16.04 machine with an NVIDIA GTX 970 GPU.}.
    AnnoCheck solves this problem through the use of programmer-provided
    annotations. Whilst CUG does this through compiler directives and an
    enhanced type system.

    \item \textbf{Sharing Code}: Despite being common when using compute
    shaders, sharing data structure definitions and other code can be difficult
    at best and impossible at worst depending on which host-shader language
    combination is being used (Section \ref{sec:shading_langauge_challenges}).
    By allowing code to be shared semantically, CUG can provide guarantees and
    a formalised way of doing this. AnnoCheck does provide basic syntactic
    code-sharing through the use of an \texttt{@include} annotation.

\end{itemize}

We have presented the technical background to provide the context and knowledge
required in order to understand the problems AnnoCheck and CUG tackle. This
includes a history of GPU APIs, an overview of the GPU pipeline, and challenges
when using shaders. We concluded the chapter with the two specific issues our
systems solve.

% For example, misnaming the shader in Vulkan, causes a
% \texttt{VK\_ERROR\_INVALID\_SHADER\_NV} error at runtime.

% % https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/vkCreateComputePipelines.html

% % https://www.khronos.org/registry/vulkan/specs/1.1-extensions/man/html/VkResult.html

\chapter{Design}

We discuss the design of AnnoCheck, a novel pre-processing system for C and
GLSL that ensures the enforcement of interfaces between the two languages.
Limitations in AnnoCheck then lead us onto CUG, a novel prototype language
which natively supports the enforcement of CPU-GPU interfaces through the use
of two distinct dialects: CUG-C and CUG-G. Whose use we described Section
\ref{sec:solutions_introduction}.

\section{Design Goals}

As we explained in Section \ref{sec:issues_summary}, the ultimate design goal
of AnnoCheck and CUG is to make programming for GPUs less frustrating and error
prone by catching errors. However, we specifically want to balance the
following concerns:

\begin{itemize}

    \item Unlike other systems which do this, we cannot have \textit{any}
    compromises to the control that existing industry standards such as GLSL
    and OpenGL provide, as many programmers still choose to use them for this
    reason (Section \ref{sec:motivation}).

    \item The design of AnnoCheck and CUG cannot be restrictive, that is, they
    should not restrict the set of possible programs that can be made relative
    to raw C and GLSL.

    \item Existing workflows need to be accounted for. For example, a commonly
    used feature is the ability to swap or reloading shaders with identical
    interfaces in-and-out at runtime \cite{HotloadShader}.

\end{itemize}

As we elaborate on in Chapter \ref{chp:related_work}, it is these design goals
that have influenced the novel aspects of both AnnoCheck and CUG.

\section{Build Strategy}

\label{sec:build_strategy}

Due to the fact that they aim to solve similar problems, both AnnoCheck and the
CUG compiler have a similar build strategy, ensuring that they work with
typical shader workflows and toolchains. We compare these strategies in Section
\ref{sec:toolchain_comparison}.

One of the reasons why it is difficult to check the consistency between shaders
and host code is the fact that shaders are loaded onto the GPU by the CPU at
run-time using API calls. Systems such as SYCL circumvent this problem by using
``single-source'' programming models - users write their shaders and host-code
in a single file, and the appropriate API calls are generated by the compiler
(Chapter \ref{chp:related_work}) \cite{SYCL}. As the compiler controls how code
is loaded-in at run-time, it can ensure that cross-language interactions are
consistent. However, in addition to preventing optimisations that could be made
to the API calls, this system has various other limitations: one of which being
able to swap and load shaders at run-time based on arbitrary logic.

This capability is important for two reasons: the first is in allowing users to
control which shaders render their applications at run-time. For example, a
game could have a high-quality shader that implements a realistic lighting
model for rendering, and a low-quality shader that is less realistic but can
run on weaker hardware. Being able to change these is important for users and
developers who wish to compare the differences. The second reason arbitrary
run-time shader loading is important, is in allowing artists to quickly iterate
shaders themselves. When designing shaders, being able to ``hot-load'' shaders
is very important. If an entire project needed to be re-compiled every time a
shader was modified, it would massively impede productivity, as changes would
take minutes, not milliseconds, to appear on-screen \cite{HotloadShader}.

Therefore, targeting the Vulkan API (Section \ref{sec:backend_choice}), we take
a novel approach in compiling CPU and GPU code separately. However, by
analysing the CPU code, we can generate metadata which is used to check for
possible errors when analysing shaders.

\section{AnnoCheck}

\label{sec:design_annotation_processor}

AnnoCheck is designed to demonstrate how existing graphics workflows using C
and GLSL (or any other C-like shader) can be improved in order to be less
error-prone, without compromising the control they provide. Furthermore, the
lessons learned from designing and implementing it influenced the design of the
CUG, which provided these benefits natively as described in Section
\ref{sec:design_languages}.

AnnoCheck is specifically designed to make the errors described in Section
\ref{sec:issues_summary} as hard to enact as possible, by making it impossible
for there to be a mis-match in the identifiers that are referred to using
strings in C, and the actual identifiers themselves in GLSL (Section
\ref{sec:resolving_identifiers}).

AnnoCheck achieves this by allowing programmers to annotate C and GLSL to mark
their \textit{intent}. Although this system is very flexible, it does have a
few issues. We evaluate all the tradeoffs this choice makes in Chapter
\ref{chp:evaluation}, and how its limitations led to the design of CUG.
However, although only employing 1000 lines of code, and being much simpler
than CUG, AnnoCheck does have a several benefits. Notably, the ability to
operate on existing C and GLSL codebases.

\section{CUG Language Design}

\label{sec:design_languages}

We have previously argued the benefits of syntactic and semantic commonality
between host and GPU code; CUG exemplifies this, and we highlight CUG-C's
features next: Firstly, those of AnnoCheck are directly integrated into the
language design. Secondly to show how, by being able to \textit{semantically}
share code with a related shading \textit{dialect} (CUG-G), code sharing can be
made much more robust than with C and GLSL. However, our approach differs from
many other custom languages which have aimed to do this. Similar to AnnoCheck,
we are not abstracting-away any API calls. Therefore CUG is theoretically
capable of the same peak-performance as C and GLSL.

Due to resource constraints, CUG does not aim to replicate \textit{all} of the
features that one would expect from an industrial language such a Java, C, C++,
C$^\sharp$, Swift, Rust, etc. Furthermore, we are not advocating for any
particular language feature that CUG implements beyond the novel ideas that ew
presents. CUG is a proof-of-concept that provides the bare-minimum feature-set
needed in order to demonstrate the ideas of this paper. However, this was still
a significant undertaking, with the CUG compiler consisting of over
\compilerloccount lines of code without comments or whitespace.

\subsection{Overall Design}

CUG (CPU-Union-GPU) is a novel proof-of-concept programming language of two
different \textit{dialects}. CUG-C (CUG-CPU), is a dialect that is designed to
target the CPU. Similarly, CUG-G (CUG-GPU), is a dialect that is designed to
target the GPU. Having two distinct dialects means that the different languages
can each have distinct features which make them more suited for their target
hardware, matching the workflow of programming for GPUs using C and GLSL. For
example, CUG-C is capable of using raw pointers, whereas CUG-G has access to
some of GLSL's built-in functions\footnote{such as normalize,reflect,sin etc.}
\cite{GLSLBuiltIn}.

However, unlike C and GLSL, where code (such as struct definitions) can be
shared \textit{syntactically}, CUG supports the \textit{semantic} sharing of
code through a common dialect of CUG-C and CUG-G: CUG-min, the subset of the
two. This means that interactions between the two languages are
\textit{well-defined}, and we can guarantee the same identifier for a given
type (eg. \textit{int}), will mean the same thing in both languages: a 32-bit
two's complement integer (unlike C and GLSL, Section \ref{sec:issues_summary}).

\subsection{Syntax}

\label{sec:language_syntax}

This section gives a brief overview of CUG's syntax. Listing
\ref{lst:cug_min_syntax} gives some examples of CUG-min; the syntax and
features that CUG-C and CUG-G share. Listings \ref{lst:cug_c_syntax} and
\ref{lst:cug_g_syntax} similarly provide examples of CUG-C and CUG-G
respectively.

\begin{lstfloat}
\begin{center} CUG-min Syntax \end{center}
\begin{lstlisting}[language=C]
// Import external module
@add "module.cug"
// 3 being assigned to a newly-declared 32-bit signed integer
var a_variable : s32 = 3;
// 5 being assigned to the existing variable
a_variable = 5;
// 5 being assigned to a 64-bit unsigned constant
let a_constant : u64 = 5;
// type inference, b_constant has type u64 as well
let b_constant := a_constant;
// compile error: constants are immutable!
/* a_constant = 10; */
// A native string datatype
let a_string : string = "Hello, I am a string";
// A struct type-definition
struct A_Struct {
    member_1 : u32;
}
// Declaring a struct variable, members *must* be named
var a_struct_variable : A_Struct = { member_1 = 10 }
// A function definition
let a_fun(a : A_Struct) => A_Struct {
    // arguments are pass-by-value
    return a;
}
// Function call
let a_struct_constant := a_fun
    // Parameters *must* be named when calling a function
    a = a_struct_variable
);
// An enum definition
enum An_Enum {
    A = 0;
    B;    // = 1
    C;    // = 2
    D = -1;
    E;    // = 0
}
// An enum variable
var a_enum_var := An_Enum.A;
// An if-statement and while loop
if a_enum_var == An_Enum.E { // Will be true
    while a_variable < 10 {
        a_variable = a_variable + 1;
    }
}
\end{lstlisting}
\caption{Examples of syntax which is valid in both CUG-C and CUG-G.}
\label{lst:cug_min_syntax}
\end{lstfloat}

\begin{lstfloat}
\begin{center} CUG-C Syntax\end{center}
\begin{lstlisting}[language=C]
// Embed arbitrary C code within the program! Mitigates CUG-C limitations.
@c_environment {
    #include <stdio.h>

    void print_ln(char const * c_str) {
        printf("%s\n", c_str);
    }
}
// Declaring the existence of an external function, it lives in 'C' namespace
@extern let print_ln(c_str: * const C::char)
// Declaring the existence of an external opaque datatype!
@extern opaque_type FILE;
// Declaring the existence of external opaque values
@extern opaque_value SEEK_END: C::int;
@extern opaque_value SEEK_SET: C::int;
@extern let fopen(
    filename: * const C::char,
    mode    : * const C::char
) => ? C::FILE
// Defining a native-wrapper that takes in-language strings
let print_ln(str: string) {
    // Use external functions/values/types with `C::`
    C::print_ln(str=to_c_string(str=str))
}
// This function is the entry-point, akin to 'main' in C.
let start() => s32 {
    print_ln(str="A string"); // Will be printed by printf!
    let a_constant : s32 = 10;
    // a nullable pointer with constant view of target
    let a_nullable_pointer : ? const s32 = null;
    a_nullable_pointer = &a_constant; // address-of, like C
    // 'malloc' operator only available in CUG-C
    let non_nullable_pointer : * s32 = malloc(s32);
    // non_nullable_pointer gets 'freed' at end of current scope
    defer free(non_nullable_pointer);
    // error, as non_nullable_pointer can't have null assigned
    /* non_nullable_pointer = null; */
    // error, as a_nullable_pointer has constant view of target,
    /* non_nullable_pointer = a_nullable_pointer */
    if a_nullable_pointer != null {
        // OK, '!' makes a nullable pointer non-nullable
        *non_nullable_pointer = *!a_nullable_pointer;
    }
    return 0;
}
\end{lstlisting}
\caption{Examples of CUG-C syntax.}
\label{lst:cug_c_syntax}
\end{lstfloat}

\begin{lstfloat}
\begin{center} CUG-G Syntax\end{center}
\begin{lstlisting}[language=C]
// A directive to verify from 'main'
@verify_from main

// Embed arbitrary GLSL code within the program! Mitigates CUG-G limitations.
@glsl_environment {
    #version 450
}

@layout(local_size_x = 1, local_size_y = 1, local_size_z = 1) in;

    // std430 is related to the packing rules
@layout(set=0, binding = 0, std430) buffer _9
{
    values: [16384] vec3;
} input_buffer;

@layout(set=0, binding = 1, std430) buffer _10
{
    values: [16384] vecv3;
} output_buffer;

}
let main()
{
    // Vec3 is available in CUG-min, making struct-sharing easier
    input : vec3 = input_buffer.values[gl_GlobalInvocationID.x];
    // CUG-G has shader functions (`normalize`), CUG-C does not
    // SEE: https://www.khronos.org/registry/OpenGL-Refpages/gl4/index.php
    output_buffer.values[gl_GlobalInvocationID.x] = normalize(input);
}
\end{lstlisting}
\caption{Examples of CUG-G syntax}
\label{lst:cug_g_syntax}
\end{lstfloat}

The syntax for CUG-C and CUG-G are based on C and GLSL respectively. The
differences between CUG-C and CUG-G are similar to those between C and GLSL,
but with more consistent semantics and syntax \cite{MissingInGLSL}. However,
CUG's syntax does differ from those C and GLSL in the following ways.

\begin{itemize}

    \item \texttt{let/var name : type = expression;} is how constants/variables
    are declared and assigned a value\footnote{This syntax is inspired by Swift
    \cite{SwiftSyntax}.}. The types of values can also be inferred by leaving
    the ``\texttt{type}'' declaration empty.

    \item Enums are namespaced. Eg. \texttt{let thing := SomeEnum.value;}.

    \item \texttt{@`command`} is the syntax for giving the compiler certain
    commands, such as importing files, generating shader interfaces, and
    declaring the existence of external symbols.

    \item All parameters in structs and function-calls must be explicitly
    assigned\footnote{There is a tradeoff here. On one hand, code-readability
    increases and breaking-changes to function interfaces are less likely to
    result in 'silent' errors. On the other hand, friction is increased when
    writing code. We do not advocate for either approach, but decided on this
    to see how it felt.}.

    \item C and GLSL code can be embedded within CUG-C and CUG-G respectively
    by wrapping them in \texttt{@c\_environment} or \texttt{@glsl\_environment}
    blocks. Similarly, symbols imported from those languages are accessed using
    the \texttt{C::} or \texttt{GLSL::} namespaces.

    \item CUG-C distinguishes \textit{nullable} (pointers which can have null
    assigned to them) and \textit{non-nullable pointers}. This was done to help
    prevent null-pointer dereferencing within graphics API calls. For example,
    many Vulkan API-calls specify which pointer arguments may or may not be
    null, but C's type system has no way of expressing this.

\end{itemize}

There are naturally many syntax and design choices in CUG that we have not
enumerated here due to space limitations.

%TODO(Content): Formal Grammar

\subsection{Semantics}

The semantics of CUG is heavily inspired by C and GLSL, and this is done for
two reasons: Firstly, it simplifies compiling CUG-C and CUG-G to C and GLSL
respectively. Secondly, our goal is to demonstrate how graphics programming may
be made less error-prone without sacrificing any of the control existing
low-level toolchains provide, and this was the simplest way to do that. Even
compiling this bare-minimum was highly demanding. We had to support all of the
language features necessary to interface with the Vulkan API. Due to this, we
limited the scope of which language features would be provided and how much our
semantics differed from C and GLSL. For example, we did not concern ourselves
with proving our type-system was sound or that CUG provided any safety
guarantees. CUG is an experimental language built from the ground-up and should
be treated as such. The upshot of this is that, barring minor syntax changes,
CUG code should be familiar to those who are familiar with C and GLSL. Section
\ref{subsec:limitations} enumerates the limitations of CUG.

\subsection{Limitations}

\label{subsec:limitations}

Being a single language with two dialects, the CUG compiler was a hefty
undertaking with over \compilerloccount lines of code. However, to prevent
feature-creep and project-bloat, we limited the scope of the dialects in the
following ways:

\begin{itemize}

    \item The design of CUG only formalises its abstract syntax, the concrete
    syntax is left underspecified (e.g. no operator precedence).

    \item CUG-C does not support arrays natively. We circumvent this by
    creating arrays in C, and passing a pointer to them into CUG-C.

    \item Although we target C and GLSL as backends for CUG-C and CUG-G, we
    perform very limited name mangling, meaning the programmer has to be
    careful about how symbols are named to ensure that they do not collide with
    any C/GLSL symbols.

    \item Compiler errors which are outside the scope of checking the CPU-GPU
    interface are limited and sometimes broken.

    \item Declarations of external symbols in C/GLSL are not checked. If they are
    incorrect, it can cause weird behaviour.

    \item CUG does not support type-casting, however, we can define external C
    functions which convert from one type to another and can call those.

    \item CUG-G does not support the programming of graphics shaders, only
    simple compute shaders. This is reflected in the chosen benchmark.

    \item CUG does not have native floating-point number support.

\end{itemize}

\subsection{C and GLSL interoperability}

In order to provide zero-overhead API calls, the CUG-C must be able to call
directly into C. This also has an additional benefit, in that C libraries can
be leveraged in order to make up for deficiencies in the language itself.

We chose to target target C as the backend for CUG-C. Although an intermediate
language such as LLVM IR would be the optimal choice for a more-developed
language, C was chosen for two reasons: It was easier to implement in the time
available, and the output of the CUG compiler can in-turn be included by
C-programs \cite{ProjectSource}. This allows automated tests of language
features, by having C++ call-into code generated by the CUG compiler (Section
\ref{sec:testing}) \cite{AutomatedTestCode} \cite{AutomatedTestOutput}.
Similarly, CUG-G targets GLSL.

The choice of these targets simplified the embedding of C and GLSL with CUG-C
and CUG-G respectively, as described in Section \ref{sec:language_syntax}. This
allowed us to easily include libraries within CUG, and helped compensate for
the limitations our languages had due to their experimental nature.

To allow embedded code to be accessed, we used an \texttt{@extern} directive to
save the compiler from having to parse that code itself. By requiring the
programmer to ensure these were consistent with embedded code, the compiler
could verify that usage of those identifiers was correct. This was purely a
time saving technique to simplify the CUG compiler.


\begin{lstfloat}
\begin{lstlisting}[language=C]
#c_environment {
    #include<stdio.h>
}

@extern let printf(format : * const C::char)

let print_fish() {
    // Note: c_str is a `magic` function that converts
    // in-language strings to c-strings. A mature
    // implementation would have a standard library that
    // provided this feature.
    C::printf(format = c_str(
        str = "fish"
    ));
    return;
}
\end{lstlisting}
\caption{Example of C-interactions. The \texttt{\#c\_environment} keyword is
used to include the \texttt{stdio.h} header. The \texttt{@extern} is used to
mark the existence of the \texttt{printf} function and define its type. As the
language does not support variadic arguments, the full interface cannot be
represented within the language.}
\label{lst:lang_c_interop}
\end{lstfloat}

Listing \ref{lst:lang_c_interop} demonstrates an example of the features used
to interact with C from CUG-G.

\chapter{Implementation}

\label{chp:implementation}

% This chapter may be called something else\ldots but in general
% the idea is that you have one (or a few) ``meat'' chapters which
% describe the work you did in technical detail.

The source code for AnnoCheck and CUG is publicly available and open-source
\cite{ProjectSource}. Although both are written in C++, Python is also used as
a build-system to enable simple cross-platform builds. These systems were
developed and tested on both the Ubuntu 16.04 and Windows 10 operating systems.
The combined source-code for both projects comes to around \totalloccount lines
of code. \compilerloccount of which are for the CUG compiler alone.

%TODO: Furthermore, the design of CUG necessitated comprehensive semantic analysis,

\section{Choice of Backend}

\label{sec:backend_choice}

We decided to target the Vulkan graphics and compute API in the implementation
of our systems \cite{Vulkan}. For the following reasons:

\begin{itemize}

    \item Vulkan is a modern graphics API with runtime safety-features (such as
    validation layers) lacked by other APIs such as OpenGL
    \cite{VulkanValidationLayers}. Our goal was to demonstrate how even a
    modern graphics API could suffer from the issues described in Section
    \ref{sec:api_challanges}, and how our systems could introduce compile-time
    checks for these errors.

    \item Vulkan is widely employed in the gaming industry, so the use-cases
    described here are applicable to a wide audience.

    \item Vulkan is a low-level API. One of the goals of our systems was to
    demonstrate how they have no runtime overhead, this is done by allowing
    users to make Vulkan API-calls directly.

\end{itemize}

\section{AnnoCheck}

\label{sec:anno_check_implementation}

AnnoCheck takes the form of a commandline program that can operate in two
modes:

\begin{itemize}

    \item \textbf{Host Mode}: indicated by the \texttt{-h} flag, allows the
    user to provide an annotated C file as input, with two outputs being given.
    The first output is indicated by the \texttt{--out-c} flag, which tells the
    annnotation processor where to output the processed C file. The second
    output is indicated by the \texttt{--out-metadata} flag, which tells the
    annotation processor where to output metadata associated with the
    annotations. This metadata is used to check GLSL files. An example command
    line instruction would be: \texttt{./annotation\_processor -h input.c
    --out-c output.c --out-metadata check.metadata}.

    \item \textbf{Shader Mode}: indicated by the \texttt{-s} flag, allows the
    user to provide annotated GLSL and metadata (generated by \textbf{Host
    Mode} as input, with GLSL being provided as the output, or an error, if the
    GLSL and the metadata are inconsistent. An example command line instruction
    would be: \texttt{./annotation\_processor -s input.glsl check.metadata
    --out-glsl output.glsl}.

\end{itemize}

Although AnnoCheck seems simple, the intention is for it to be used as a
command-line program that can be used within more comprehensive build systems.
We describe such a toolchain in Section \ref{sec:toolchain_comparison}.

AnnoCheck works by looking for custom ``\texttt{@}'' directives within C or
GLSL code. When such a directive is found, it tokenises and parses the relevant
sections of the provided input using a recursive descent parser, creating an
abstract syntax tree.

For annotated C code, this AST is semantically analysed in order to produce
metadata, which is saved in an output file. This metadata needs to be to fed to
AnnoCheck when analysing annotated GLSL, so it can verify that the annotations
within it are consistent with the annotated C. Although this build system may
seem cumbersome, as we discuss in Section \ref{sec:sec:build_strategy}, by
generating metadata from annotated C once, GLSL can be re-compiled and
``hot-loaded'' at runtime. After analysing either annotated C or GLSL,
AnnoCheck outputs the C and GLSL files with all the annotations removed, so
that they can be compiled handled as regular C and GLSL by the rest of the
programmer's build system.

\section{CUG Compiler Implementation}

The CUG compiler is a much more complex endeavor than AnnoCheck, compromising
of \compilerloccount lines of code. CUG is a single program which is able to
compile code written in three dialects of CUG: CUG-C, CUG-G, and the subset of
the two, CUG-min. Input for the CUG compiler is achieved in a similar manner to
the input into AnnoCheck, with the compilation of CUG-C generating a metadata
output file which needs to be fed as input when analysing CUG-G programs. An
example of this is given in Section \ref{sec:toolchain_comparison}.

\subsection{Compiler Pipeline}

\label{sec:compiler_pipeline}

\begin{figure}[h]
\centering
\def\svgwidth{\linewidth}
\scriptsize{\input{images/cug_compiler_pipeline.pdf_tex}}
\caption{The CUG compiler pipeline. Arrows indicate the flow of data from
input to output. Boxes represent compiler stages.}
\label{fig:cug_compiler_pipeline}
\end{figure}
%TODO: nive tge furst arriw up top to possibly allow larger text.
%TODO(Error!): Fix the typo in 'Generate output' (C in both!)

Figure \ref{fig:cug_compiler_pipeline} shows the CUG compiler, with the
stages handled in the following ways:

\begin{itemize}

    \item \textbf{Set Internal Dialect State}: Depending on whether a CUG-C,
    CUG-G or CUG-min file is being processed, set the internal compiler state
    associated with that file to the appropriate value (Section
    \ref{sec:internal_state_machine}).

    \item \textbf{Tokenise Input}: Perform lexical analysis and tokenise the
    input file. Invalid tokens can result in compilation errors here which are
    reported back to the user. The set of valid tokens depends on dialect state
    associated with a given file. (eg. CUG-C does not support
    \texttt{@glsl\_environment} tokens).

    \item \textbf{Parse Input}: Parse input and generate abstract syntax tree
    of the language. We implemented this using a custom recursive descent
    parser. The dialect state has little affect on parsing as syntax-tree
    generation should be consistent between all the dialects.

    \item \textbf{Parse Imported Modules and Metadata}: Recursively perform the
    ``parse input'' step on imported modules, and metadata that may be imported
    by CUG-G code.

    \item \textbf{Semantically Analyse Imported Modules and Metadata:} Perform
    semantic analysis of imported modules and metadata. This is done using a
    custom symbol table which employs the FNV hashing algorithm \cite{FNVHash}.

    \item \textbf{Semantic Analyse}: Resolve types and identifiers on the
    program. This step is where most dialect-state specific work is done. Other
    properties are examined as well, such as the presence of cycles in struct
    definitions.

    \item \textbf{Generate IR (Intermediate Representation)}: Generate a
    lower-level intermediate representation of the code. This is done in order
    to simplify the process of outputting to C. Our IR consists of a custom
    three address code system, with quadruples used as the datastructure to
    represent them \cite{ThreeAddressCode}. All frontends share the same IR,
    however, certain quadruples can only be generated for certain backends (eg.
    pointers and malloc are only available in CUG-C). All name-mangling is
    performed here, and all the modules are rolled into a single data structure
    which contains all the IR needed for the final output.

    \item \textbf{Generate Final Output:} Depending on the internal state
    associated with the root file, generate the final C or GLSL output.

\end{itemize}

\subsection{The Internal State Machine}

\label{sec:internal_state_machine}

In order to ensure that CUG-C and CUG-G can share code semantically, code
written in these dialects share the same compiler. This ensures that there are
not any unexpected differences in how the programs are parsed, especially when
sharing modules between the two dialects. This differs substantially from C and
GLSL, which do have peculiar differences which means that sharing code can
result in unexpected behaviour (Section
\ref{sec:sec:shading_langauge_challenges}).

We achieve this through the use of an internal state machine within the
compiler, where each module is associated with one of the following states:

\begin{itemize}

    \item \textbf{\texttt{HOST}:} When in the \texttt{HOST} state, the CUG
    compiler ensures that it only compiles code that conforms to the CUG-C
    dialect.

    \item \textbf{\texttt{SHADER}:} When in the \texttt{SHADER} state,
    similarly, only CUG-G code can be compiled.

    \item \textbf{\texttt{SHARED}:} When in the \texttt{SHARED} state, only
    CUG-min is parsed.

\end{itemize}

Originally we were intending to employ two modes of operation, similar to
AnnoCheck (Section \ref{sec:anno_check_implementation}). However, this was
replaced by a state machine for the following three reasons:

\begin{itemize}

    \item The CUG compiler can transition from the CUG-C or CUG-G state to the
    CUG-min state, when either include a CUG-min module.

    \item Although the CUG-G dialect can only be compiled to compute shaders,
    an industrial compiler of this nature would need to be extended to support
    other shader types such as vertex, pixel and geometric shaders. These all
    have subtle differences in permitted operations and behaviour -- extending
    the state machine so that these could be handled would be trivial.

    \item As we discuss in Chapter \ref{chp:related_work}, there has been some
    movement towards ensuring ``single-source'' (where shaders are embedded
    within a C++ program) programs and ``multi-source'' (what we are doing)
    programs use similar semantics, so that code from communites which use each
    can be shared. Theoretically, we could extend the CUG compiler to allows
    programmers to embed CUG-G programs within CUG-C ones.

\end{itemize}

This state is preserved throughout the entire compilation pipeline (Section
\ref{sec:compiler_pipeline}), affecting each of the compilation stages in
different ways. Including code from other source-files (which we call module
imports) is affected by the state machine:

\begin{itemize}

    \item CUG-C files can include both CUG-C and CUG-min files.

    \item CUG-G files can include CUG-G files, CUG-min files and generated
    CUG-C metadata (which is generated when a CUG-C file is compiled, and is
    used to validate the interface of a CUG-G file).

    \item CUG-min files can only include other CUG-min files.

\end{itemize}

%TODO: mention benefit somewhere about CUG-C being able to use GLSL shaders and
% CUG-G being callable from C.

These relationships determine which state transitions are valid, and also are
the mechanism through-which code is shared between CUG-C and CUG-G.

\subsection{Testing}

\label{sec:testing}

Whilst features in the CUG language were being incrementally developed, it was
important to ensure that existing features were behaving as expected as soon as
possible -- as we could therefore ensure that none of the features ever
regressed. However, using CUG to test itself would not have been ideal, as
errors within the language could lead to vacuously true results.

To solve this problem, we took advantage of the fact that our CUG-C input was
compiled to C, by using a C++ testing framework to call-into CUG-C functions
and test that the results returned matched what was expected. This feature
proved invaluable, and caught many errors. The biggest difficulty was
working-around the name-mangling the CUG compiler performed, but fortunately it
was predictable and consistent.

This process formed the foundation for an automatic regression-testing system,
which we ran automatically on every commit to the main repository
\cite{ProjectSource} \cite{AutomatedTestCode} \cite{AutomatedTestOutput}.

\chapter{Evaluation}

\label{chp:evaluation}

This chapter evaluates how AnnoCheck and CUG compare with the traditional
unchecked C and GLSL toolchain. We do this by employing a sample program called
\textit{FishCopy}, comparing aspects such as toolchain complexity, code
samples, errors which AnnoCheck and CUG prevent, and runtime performance. Due
to the complexity of using the Vulkan API, we will present small samples of
this program. The full version of \textit{FishCopy} can be found on the project
GitHub repository \cite{ProjectSource}. For example, the C code which makes the
appropriate API calls to run a simple compute shader that copies items from one
file to another is over 750 lines long. The example is adapted from an
open-source sample program \cite{VulkanComputeExampleSource}.

\section{Fishcopy}

\textit{Fishcopy} consists of a CPU program which performs the necessary work
to invoke a simple compute shader. CPU fills an array with 16384\footnote{This
value was arbitrarily chosen but is a power-of-two, $2^{13}$} values which are
of the type \texttt{Fish}. \texttt{Fish} is a simple struct whose definition is
given in Listing \ref{lst:struct_fish}.

\begin{lstfloat}
\begin{lstlisting}[language=C]
struct Fish{
    int num_eyes;
    int num_fins;
}
\end{lstlisting}
\caption{The \texttt{struct} definition for the \texttt{Fish} type.}
\label{lst:struct_fish}
\end{lstfloat}

All the values in the array are then assigned a random integer value using the
C library's \texttt{rand()} function \cite{RandRef}. After the array has been
initialised, its contents are transferred to a buffer on the GPU. The CPU then
invokes a simple compute shader which copies the data across to another buffer
(Section \ref{sec:shader_comparison}). The CPU then confirms that this output
matches the original input.

Although Fishcopy is simple, it serves two purposes: Firstly, to demonstrate
how both CUG and AnnoCheck catch errors which may easily be made in even a
simple program. Secondly, to show the benefits that CUG provides over
AnnoCheck.

\section{Shader Comparison}

\label{sec:shader_comparison}

Listings \ref{lst:glsl_shader}, \ref{lst:anno_check_shader} and
\ref{lst:cug_g_shader} display the FishCopy shader written in GLSL, annotated
GLSL and CUG-G respectively.

\begin{lstfloat}
\begin{center}
FishCopy GLSL Shader
\end{center}
\begin{lstlisting}[language=C]
#version 450
struct Fish {
    int num_eyes; int num_fins;
};
const int BUFFER_LENGTH = 16384;
layout(local_size_x = 1, local_size_y = 1, local_size_z = 1) in;
layout(set=0, binding = 0, std430) buffer _9
{ Fish values[BUFFER_LENGTH]; } input_buffer;
layout(set=0, binding = 1, std430) buffer _10
{ Fish values[BUFFER_LENGTH]; } output_buffer;
void main()
{
    output_buffer.values[gl_GlobalInvocationID.x].num_eyes = input_buffer.values[gl_GlobalInvocationID.x].num_eyes;
    output_buffer.values[gl_GlobalInvocationID.x].num_fins = input_buffer.values[gl_GlobalInvocationID.x].num_fins;
}
\end{lstlisting}
\caption{GLSL version of FishCopy shader. Without helper-tools, the
\texttt{Fish} needs to be manually included in the shader file.}
\label{lst:glsl_shader}
\end{lstfloat}

\begin{lstfloat}
\begin{center}
AnnoChecked FishCopy GLSL Shader
\end{center}
\begin{lstlisting}[language=C]
#version 450
@include "struct.h"
layout(local_size_x = 1, local_size_y = 1, local_size_z = 1) in;
// std430 is related to the packing rules
layout(set=0, binding = 0, std430) buffer _9
{ Fish values[BUFFER_LENGTH]; } input_buffer;
layout(set=0, binding = 1, std430) buffer _10
{ Fish values[BUFFER_LENGTH]; } output_buffer;
@verify(from: "verification_1", function:
void main() {
    output_buffer.values[gl_GlobalInvocationID.x].num_eyes = input_buffer.values[gl_GlobalInvocationID.x].num_eyes;
    output_buffer.values[gl_GlobalInvocationID.x].num_fins = input_buffer.values[gl_GlobalInvocationID.x].num_fins;
})
\end{lstlisting}
\caption{AnnoChecked version of the GLSL FishCopy shader. AnnoCheck provides
the \texttt{@include} annotation for including C structs. However, this does
have its dangers (Section \ref{sec:shading_langauge_challenges}). The \texttt{@verify} directive
verifies that the main function conforms to expectations.}
\label{lst:anno_check_shader}
\end{lstfloat}

\begin{lstfloat}
\begin{center}
FishCopy CUG-G Shader
\end{center}
\begin{lstlisting}[language=C]
@add "module.cug"
// ensures that the interfaces in this module match the one generated by main
@verify_from "main.cugc"
@glsl_environment {
    #version 450
}
@layout(local_size_x = 1, local_size_y = 1, local_size_z = 1) in;
@layout(set=0, binding = 0, std430) buffer _9
{ values: [BUFFER_LENGTH] Fish; } input_buffer;
@layout(set=0, binding = 1, std430) buffer _10
{ values: [BUFFER_LENGTH] Fish; } output_buffer;
let main()
{
    output_buffer.values[gl_GlobalInvocationID.x].num_eyes = input_buffer.values[gl_GlobalInvocationID.x].num_eyes;
    output_buffer.values[gl_GlobalInvocationID.x].num_fins = input_buffer.values[gl_GlobalInvocationID.x].num_fins;
}
\end{lstlisting}
\caption{CUG-G FishCopy shader. Custom directives allow for CUG-min modules to
be included. }
\label{lst:cug_g_shader}
\end{lstfloat}

One aspect worth noting, is that the \texttt{Fish} struct must be manually
defined in the raw GLSL shader, as \texttt{\#include} directives are not
supported within the language \cite{NoIncludeGLSL}. For our own convenience,
AnnoCheck provides an \texttt{@include} annotation, which does this for us,
allowing code to be shared. However, as we discussed in Section
\ref{sec:shading_langauge_challenges}, this sharing is purely syntactic, and C
and GLSL do have some differences which can complicate code sharing. This is
primarily why we developed CUG, as the CUG-G shader includes the same module as
the CUG-C program which invokes it. As this sharing is \textit{semantic}, we
can provide guarantees that CUG-G and CUG-C will use this module in compatible
ways.

AnnoCheck and the CUG-G shader both use different mechanisms for verification:
with AnnoCheck, annotations are applied to regular GLSL code, whilst CUG-G
handles verification through the CUG type system (Section
\ref{sec:resolving_identifiers}).

\section{Toolchain Comparison}

\label{sec:toolchain_comparison}

Figures \ref{fig:pipeline_basic}, \ref{fig:pipeline_anno_check},
\ref{fig:pipeline_cug} and \ref{fig:pipeline_cug_future} compare the build
process of FishCopy for different graphics toolchains. We managed the build
process for all these configurations using a simple Python script.

\begin{figure}[h]
\centering
\def\svgwidth{0.8\linewidth}
\input{images/pipeline_basic.pdf_tex}
\caption{How the C and GLSL version of FishCopy is compiled and run. GLSL lacks
an \texttt{\#include} directive, meaning that programmers need to manually
ensure that shared code is compiled into the shader.}
\label{fig:pipeline_basic}
\end{figure}

Figure \ref{fig:pipeline_basic} shows how the raw C and GLSL versions of
Fishcopy are compiled and executed. In this instance, the \texttt{Fish} struct
is defined in a file called struct.h, which is included in the main program
using C's \texttt{\#include} directive. However, as previously discussed, it
needs to be manually inserted into the shader \cite{NoIncludeGLSL}. This
naturally increases the complexity of this toolchain. We compile main.c to an
executable using clang, and we compile the shader to SPIR-V using the Khronos
Group's GLSL to SPIR-V compiler,\textit{glslang} \cite{Clang} \cite{glslang}.

When the executable runs, it performs all the API calls necessary to load the
compiled SPIR-V shader and execute it on the GPU.

\begin{figure}[h]
\centering
\def\svgwidth{0.8\linewidth}
\input{images/pipeline_annocheck.pdf_tex}
\caption{The AnnoCheck-supported build process for FishCopy. AnnoCheck includes
directives which allow C headers to be inserted into GLSL shaders. However, this
comes with no guarantees about the correctness of doing so.}
\label{fig:pipeline_anno_check}
\end{figure}

Figure \ref{fig:pipeline_anno_check} demonstrates the AnnoCheck version of this
toolchain. As can be seen, there is an extra level of complexity here compared
with the C and GLSL version. The process is derived from that for raw C and
GLSL, but with a couple of minor differences. Firstly, AnnoCheck processes the
annotations in main.c in order to generate a metadata file,
\textit{annotations.meta}, that is used to verify the code in the shader. The
second difference is that AnnoCheck is able to perform the same file-inclusion
capabilities for the shader that previously had to be executed manually. The
shader is successfully verified if, only if the annotations within it are
consistent with those main.c.

From this point on, the build process is identical to raw C and GLSL, with the
generated C and GLSL files matching the raw C and GLSL files identically -- the
annotations are simply stripped-out by AnnoCheck after the annotated input
files have been verified.

\begin{figure}[h]
\centering
\def\svgwidth{0.8\linewidth}
\input{images/pipeline_cug.pdf_tex}
\caption{The build process for the CUG version of FishCopy. CUG-C and CUG-G
semantically share the same module. However, compiling to C and GLSL
complicates the build process.}
\label{fig:pipeline_cug}
\end{figure}

Figure \ref{fig:pipeline_cug} demonstrates the CUG toolchain we implemented. In
contrast to the simple syntactic sharing of the \texttt{Fish} definition in
both the raw and AnnoCheck toolchains, the module containing \texttt{Fish} is
shared semantically between CUG-C and CUG-G. However, the toolchain complexity
is increased by the need to compile the resulting C and GLSL that is generated
by the CUG compiler.

\begin{figure}[h]
\centering
\def\svgwidth{0.8\linewidth}
\input{images/pipeline_cug_future.pdf_tex}
\caption{If the CUG compiler could generate SPIR-V and x86 itself, then the build
process would be simpler.}
\label{fig:pipeline_cug_future}
\end{figure}

Figure \ref{fig:pipeline_cug_future} illustrates how an idealised CUG toolchain
would appear if CUG-G was compiled directly to SPIR-V and if CUG-C was compiled
directly to x86.

All the toolchains make different tradeoffs. The raw C and GLSL toolchain is
the simplest, but suffers from requiring programmers to use custom solutions
for code-sharing between C and GLSL \cite{NoIncludeGLSL}. Furthermore,
interactions between C and GLSL are completely unchecked -- programmer
discipline being required to ensure bug or erroneous behaviour does not occur
when making API calls. AnnoCheck increases the toolchain complexity, in
exchange for allowing the programmer to annotate their code such that AnnoCheck
can prevent some errors from happening. Futhermore, AnnoCheck can also handle
code-inclusion in GLSL, removing the need for that to be done by a custom
solution. The CUG compiler is part of the most complex toolchain. However,
Figure \ref{fig:pipeline_cug_future} demonstrates that if properly implemented
CUG could reduce the overall toolchain complexity. Especially as it provides
standardised methods for semantically sharing code between host and shader code
(in this case, CUG-C and CUG-G).

\section{Error-Prevention}

In this section we analyse each of the errors shown in Section
\ref{sec:issues_summary}, demonstrating how both AnnoCheck and CUG prevent the
programmer from committing them.

\subsection{Resolving Identifiers}

\label{sec:resolving_identifiers}

This is an issue solved by both AnnoCheck and CUG. As we discuss in Section
\ref{sec:issues_summary}, host code often has to refer to identifiers which are
mentioned in shaders through the use of strings. However, this is problematic,
for two reasons: Firstly, the identifiers are not resolved until runtime, when
API calls are made by the CPU that refer to identifiers within a shader that
has been loaded onto the GPU. Secondly, it makes refactoring tools harder to
implement, as there is no logical connection between strings in a host language
and identifiers within a shader that can be statically determined.

This is the primary issue that AnnoCheck aims to resolve, and one of the
features that CUG handles within its cross-dialect type system. Section
\ref{sec:shader_comparison} compares the raw GLSL shader, the annotated GLSL
shader, and the CUG-G shader. Listings \ref{lst:invoke_main_c},
\ref{lst:invoke_main_anno} and \ref{lst:invoke_main_cugc} show how each of
these systems invoke the \texttt{main} function within the shader.

\begin{lstfloat}
\begin{lstlisting}[language=C]
VkPipelineShaderStageCreateInfo shader_stage_create_info = {
  .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
  .pNext = 0,
  .flags = 0,
  .stage = VK_SHADER_STAGE_COMPUTE_BIT,
  .module = shader_module,
  .pName = "main",
  .pSpecializationInfo = 0
};
\end{lstlisting}
\caption{The C declaration and initialisation of the datastructure needed to
identify the correct function within the GLSL shader. We use designated initialisers
in C\cite{DesignatedInitC}.}
\label{lst:invoke_main_c}
\end{lstfloat}

Listing \ref{lst:invoke_main_c} demonstrates the C implementation of creating a
\texttt{VkPipelineShaderStageCreateInfo} data structure instance. This
structure is employed by the Vulkan API to identify \texttt{main}, using a
string. This is similar to the example shown in Listing
\ref{lst:annotation_example_output}. On our machines, modifying this string led
to a runtime crash of the FishCopy program.

\begin{lstfloat}
\begin{lstlisting}[language=C]
VkPipelineShaderStageCreateInfo shader_stage_create_info = @create_verification(
  struct: VkComputePipelineCreateInfo,
  name: "verification_1",
  info: {
    .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
    .pNext = 0,
    .flags = 0,
    .stage = VK_SHADER_STAGE_COMPUTE_BIT,
    .module = shader_module,
    .pName = "main",
    .pSpecializationInfo = 0
  }
);
\end{lstlisting}
\caption{The AnnoChecked version of what is shown in Listing
\ref{lst:invoke_main_c}. The struct initialisation is wrapped by an annotation
which is used to ensure that the shader \texttt{main} exists when the
AnnoChecked shader is processed.}
\label{lst:invoke_main_anno}
\end{lstfloat}

Listing \ref{lst:invoke_main_anno} demonstrates how the C sample can be
annotated. Deliberately misnaming \texttt{"main"} and processing this with
AnnoCheck will generate a metadata file, that will result in AnnoCheck telling
the programmer that the GLSL programmer is missing the identifier that the C
program refers to.

\begin{lstfloat}
\begin{lstlisting}[language=C]
let shader_name : ShaderName = @verified_shader_function(main);
let compute_pipeline_create_info :
 C::VkPipelineShaderStageCreateInfo = {
  sType               = VkStructureType.VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
  pNext               = null,
  flags               = VkPipelineShaderStageCreateFlags.none,
  stage               = VkShaderStageFlagBits.VK_SHADER_STAGE_COMPUTE_BIT,
  module              = shader_module,
  // Below is type-checked thanks to @verified_shader_function
  pName               = shader_name, // entry point of the function
  pSpecializationInfo = null
};
\end{lstlisting}
\caption{The CUG-C initialisation of the relevant shader name. The interface of
the struct has been modified slightly so that its \texttt{pName} field is of
type \texttt{ShaderName}. This strongly encourages the programmer to use the
directives which generate the code necessary for verifying CUG-G.}
\label{lst:invoke_main_cugc}
\end{lstfloat}

Listing \ref{lst:invoke_main_cugc} similarly shows the CUG-C sample. Here, the
\texttt{pName} member in the initialisation struct is declared as having the
type \texttt{ShaderName} instead of a character pointer. This enforces a system
where the programmer must use a compiler directive which performs the same
functionality as AnnoCheck.

\section{Performance and Discussion}

One of the key goals of both AnnoCheck and CUG is to not compromise the
low-level control raw graphics APIs provide. This section discusses how the
performance of AnnoCheck and CUG compare versus raw C and GLSL, followed by the
tradeoffs that a low-level abstraction layer makes.

\subsection{AnnoCheck versus raw C and GLSL}

AnnoCheck is an annotation system that \textit{enhances} C and GLSL. We
designed it so that simply removing the annotations from any program which uses
AnnoCheck results in plain and valid C and GLSL. This means that the set of
AnnoCheck-enabled programs is a superset of valid C and GLSL programs. Although
this makes a few tradeoffs \ref{sec:performance_tradeoffs}, a benefit is that
after AnnoCheck processes a program, the output is identical to what would be
written in C or GLSL.


\subsection{CUG versus raw C and GLSL}

CUG shares many of its semantics with C and GLSL, which in theory should mean
that any CUG program should have identical performance to an equivalent C GLSL
program by design. However, as a novel language, we parse, analyse and convert
CUG to an intermediate representation before outputting the results to a C
back-end. This is a destructive operation in contrast to AnnoCheck's solution.

Therefore, when compared the runtime performance of CUG implementation of
FishCopy with the one written in C and GLSL. As expected, the C and GLSL
implementation slightly outperformed the CUG implentation. Although this may
initially appear a trivial point, it has importance, as the maturity of
optimisation tools for existing languages give them a significant incumbent
advantage \cite{RustSlow}. Therefore, although a language can be carefully
designed with semantics which enable high-performance programs, the
implementation which achieves that is an important barrier to overcome.

\subsection{Tradeoffs}

\label{sec:performance_tradeoffs}

AnnoCheck and CUG both make similar tradeoffs when it comes to the overall
performance: They give the programmer control over low level details. This
differs substantially from the approach much research has taken, where these
are abstracted in favour of allowing an optimising compiler to handle them.
Whilst the low level details are still important in many domains such as games,
which have hard real-time constraints, as we discuss in Chapter
\ref{chp:related_work}, some optimising compilers have been able to outperform
manually-written code.

\section{Conclusion}

We have evaluated four components of AnnoCheck and CUG: How code is written,
the toolchain complexity, how errors are prevented, and the performance
tradeoffs both systems make. By requiring annotations and a new tool, AnnoCheck
does increase both the complexity of code and the complexity of the toolchain
relative to raw C and GLSL. However, the benefit of this is that it can handle
syntactic code sharing for the user and catch identifier mis-matches.
Futhermore, it has identical performane to raw C and GLSL.

CUG makes different tradeoffs, as code has to be written in an entirely new
language, but CUG-C and CUG-G can semantically share code. Futhermore, the type
system enforces the usage off AnnoCheck-like annotations. Although our CUG
implementation had the most complex toolchain, a complete compiler would be
more simple than the toolchain needed for raw C and GLSL.

\chapter{Related Work and Discussion}

%TODO(Rewrite) Rewrite this so that comments on the related work is made

%TODO: interesting point, how our annotation system differs from the one where
% you can annotate portable C++ (find out which it is)

\label{chp:related_work}

We detail related work in the field of modifying or improving GPU toolchains
beyond traditional low-level libraries. We demonstrate the diverse set of
approaches that have been employed in this area and the progress made, whilst
demonstrating how the specific problems targeted by AnnoCheck and CUG have yet
to be addressed.

Since the creation of the SPIR-V intermediate language for heterogeneous
programming (as discussed in Chapter \ref{chp:technical_background}), some
progress has been made in simplifying and unifying how GPUs are interacted with
for compute purposes. For example the Khronos Group have recently standardised
a modified version of C++, \textit{OpenCL C++} for developing compute shaders
\cite{OpenCL22Release} \cite{OpenCLCPPWhitePaper} \cite{OpenCL}. This has only
been possible because it can be compiled to SPIR-V, whereas previously graphics
drivers had to implement OpenCL C directly, limiting how complex OpenCL's
shader language could become. However, whilst unifying some aspects of host and
shading languages, this uses the traditional workflow of programming compute
kernels and host code separately, with no cross-module checking at the API
boundaries \cite{OpenCL22Release}.

SYCL is a framework by the Khronos Group built on top of OpenCL that abstracts
away the API calls to enable ``single-source'' C++ development which
automatically generates host and shader code from a single C++ source file
\cite{OpenCL22Release} \cite{SYCL}. SYCL has seen uptake in multiple
implementations, and has been adopted as a backend for various machine learning
frameworks such as TensorFlow and Eigen \cite{ComputeCPP} \cite{triSYCL}
\cite{SYCLTensorFlow} \cite{SYCLEigen}. However, this approach does have its
limitations by removing the ability for developers to control how those API
calls are made, which AnnoCheck and CUG preserve. Both OpenCL and SYCL are also
limited in only being suitable for \textit{compute} applications, and do not
allow for the graphics operations for which GPUs are capable. However, Vulkan
and OpenCL may merge in the future, which could open the door to this happening
\cite{VulkanOpenCLMerge}.

Research has been done to make GPU and heterogeneous computing available in
high-level dynamic languages. Theano and TensorFlow do this by abstracting a
compute platform such as OpenCL or CUDA using a framework or library
\cite{Theano2016} \cite{TensorFlowWhitePaper}. This technique has primarily
seen success in scientific computing and machine learning. Others have created
custom high-level languages which target GPUs directly. Harlan, developed by
Holk et al., is a GPU-targeted domain-specific language (DSL) based on Scheme,
with support for higher order programming with Scheme-influenced syntax and
semantics \cite{Harlan} \cite{HarlanAnnouncement}. GPipe extends the functional
language Haskell such that shaders can be written functionally and OpenGL calls
can be made in type-safe ways. However, the garbage-collection of Haskell makes
it unsuitable for many of the domains in which GPUs are employed, such as games
\cite{HaskellState} \cite{GPipe}. Halide is a DSL for image processing and
computational photography \cite{Halide}. Fumero et al. have developed
techniques to automatically offload computation from high-level interpreted
dynamic languages using just-in-time compilation to achieve speedups by
compiling R to an OpenCL C backend \cite{JITGPU}. Futhark is an attempt to
design a functional data-parallel array language from the ground-up that can
target GPUs through an OpenCL backend \cite{Futhark}.

Existing languages have also been extended with the functionality to compile
parts of their programs to heterogeneous architectures. Lime and JCUDA take the
approach of compiling Java or Java-like code in such a manner \cite{Lime2010}
\cite{Lime2012} \cite{JCUDA2009}. However, they differ in their approaches.
Lime aims to abstract low-level details of heterogeneous computing such that
arbitrary backends may be targeted, including GPUs (using OpenCL as a back-end)
and FPGA synthesisation. JCUDA targets CUDA, allowing CUDA programs to be
created using Java, with an interface that aims to closely match CUDA's native
C API. OpenACC is a system for scientists that allows programmers to mark
appropriate sections of normal C++, C or Fortran code as possible candidates
for accelerated parallel computation \cite{OpenACC}. The specific goal being to
allow users to write code as they normally would for the CPU, and then add
directives to code fragments as hints to the compiler that such fragments could
perform optimally if run on a GPU.

%TODO: Above, compare OpenACC with AnnoCheck.

Another approach that has been taken is to abstract away underlying APIs such
as CUDA and OpenCL with platforms that can target both as backends. HIP is a
project that does this by allowing CUDA code to be compiled to C++. It uses an
abstracted API in order that developers may convert their CUDA projects to
something that can target non-NVIDIA backends \cite{HIP}.

In addition to SYCL and OpenCL C++, there have been other attempts at bringing
heterogeneous programming models natively to C++ through parallel programming
standards. C++ AMP is a C++ library, programming model, and compiler developed
by Microsoft that targets Direct3D 11 \cite{CAMP}. However, it appears to have
been abandoned \cite{CAMPFail1} \cite{CAMPFail2}. \textit{C++ extensions for
parallelism} has brought such standards to the C++ standard template library
\cite{CPPParallelism}. Finally, OpenMP is an API standard dedicated to
shared-memory multiprocessing \cite{OpenMP}. HCC is a project that aims to take
C++ code conforming to any of these standards and compile it to AMD's GCN
instruction set \cite{HCC}.

\section{Discussion}

As can be seen, there has been some progress in making programming for
heterogeneous architectures and GPUs easier. However, the focus has been on
GPGPU computing, with limited research on graphics programming. Futhermore,
although the creation of SPIR-V and Vulkan are slowly changing this, all of
these systems have had to target fairly-high level backend APIs such as OpenCL
or CUDA, in addition to languages compiled by device drivers such as
\textit{OpenCL C} or \textit{CUDA C/C++}, which has limited the performance and
stability of the higher-level systems \cite{GLFuzz}. Additionally, apart from
\textit{Open CL C++}, these all either present alternate high-level interfaces
or abstract them away in order to ensure simplified and less error-prone
programs. This differs from the approach we take, which is to mark-up low-level
API calls directly, so that they are checked at compile-time for consistency
without sacrificing the control that would otherwise be lost by abstractions.
Furthermore, although we could only test a compute shader, the design of
AnnoCheck and CUG is amenable to being used for graphics programming.

% TODO(Helpful): Future roadmap confusion

% TODO(Helpful): Vulkan Validation Layers

\chapter{Conclusion and Further Work}

\label{chp:conclusion_and_further_work}

% As you might imagine: summarizes the dissertation, and draws
% any conclusions. Depending on the length of your work, and
% how well you write, you may not need a summary here.

% You will generally want to draw some conclusions, and point
% to potential future work. \cite{DirectXWorkings}

We have shown two novel systems, AnnoCheck and CUG, which can make programming
for GPUs using conventional low-level APIs less error-prone. AnnoCheck, an
annotation processor for C and GLSL, aims to demonstrate how existing workflows
which use these languages can be improved in this way, without sacrificing
performance. Leading on from this, CUG, demonstrates how a compiler can
integrate these checks, whilst still allowing programmers to use the low-level
C APIs and writing their shaders explicitly. Furthermore, CUG enables the
\textit{semantic} sharing of code between CPUs and GPUs, as opposed to the
syntactic sharing that occurs between C and GLSL. Although CUG is more powerful
than AnnoCheck, AnnoCheck is a much simpler program and the techniques it
employs could be used with existing C and GLSL code bases.

Although our implementations do work in some simple cases, there is still much
more work that could be done and places where they could be taken. Furthermore,
as covered in Section \ref{sec:api_challanges}, there are still many unsolved
problems with using graphics APIs. Semantic code-sharing in particular presents
the following opportunities:

\begin{itemize}

    \item A concretely designed ``single-source'' programming model, without
    the ``integration discontinuity'' that current models such as SYCL
    have\footnote{That is, the ability to iteratively migrate from a
    ``single-source'' system to a ``multi-source'' one, when the costs of
    single-source programming outweight the benefits over the course of a
    project's lifecycle.} \cite{DesignAndEvaluateReusableComponents}.

    \item Software-side debugging. That is, the ability to inform the compiler
    to compile specific shaders for the CPU. This would be desirable to
    simplify the debugging them during development. However, it would require a
    software implementation of the Vulkan API, which has yet to exist
    \cite{VulkanCPU} \cite{Kazan}, \cite{SwiftShaderVulkan}.

    \item The ability to support other dialects beyond one for the CPU and one
    for the GPU. For example, different dialects could exist for different
    target architectures, in addition to different dialects existing which
    provide different language features. However, the tradeoff here is that
    increasing the number of dialects would increase the complexity of the
    compiler.

\end{itemize}

% TODO(Content):

% SUPPORT DIFFERENT STATES OF GPU LANGUAGES BASED ON TARGET PART OF PIPELINE.

Something which the creation of SPIR-V enables, and that this paper
demonstrates is possible, is the ability to \textit{extend} languages with
custom shading languages whilst still preserving existing API interfaces. This
is different from that currently done both in industry and reasearch. For
example, whilst programs for the Unity game engine are written in C$^\sharp$,
shaders for it have to be written in HLSL \cite{UnityShaders}. Projects such as
SYCL and Lime did extend C++ and Java respectively to allow shaders to be
programmed in their host languages, however they used optimising compilers with
the goal of abstracting away the underlying OpenCL API and outputting OpenCL C
code for shaders. However, OpenCL C++ has demonstrated that API interfaces can
be preserved whilst shaders are written in the host language
\cite{OpenCLCPPWhitePaper}. This also means that SYCL can use this compiler in
its backend \cite{SYCL}.

This leads into the approach I expect other high-level languages to take in the
future as, briefly summarised below:

\begin{itemize}

    \item Port desired graphics and compute APIs such as OpenGL, OpenCL and
    Vulkan to your language so that they can be called directly from it.

    \item Create a modified extension of your language that can be used to
    program shaders, the compiler for this extension can target SPIR-V.

    \item Use any features your language may have to increase the safety of
    specific API calls using techniques similar to what has been demonstrated
    in this paper. Alternatively custom annotations may be used to strengthen
    this system.

    \item Create ``single source'' abstractions which an optimising compiler
    can use to generate appropriate API calls for your computations, taking
    advantage of your shader compiler. The relationship here can be similar to
    the one between SYCL and OpenCL C++.

\end{itemize}

The benefits of this approach is that the GPU ecosystem will more closely
resemble the ``hourglass model'' that CPUs enjoy today, instead of the separate
fragmented ecosystems it currently suffers. Eventually, the higher-level OpenCL
and OpenGL could be APIs which are implemented in terms of the lower-level
Vulkan, bringing this ``dream'' another step closer to reality
\cite{OpenGLonVulkan} \cite{VulkanOpenCLMerge} \cite{OpenGLOverload}.

% TODO(Helpful): Software renderer + Vulkan CPU for CPU side debugging


\bibliographystyle{unsrt}
\bibliography{references}

\appendix
\singlespacing

\end{document}
