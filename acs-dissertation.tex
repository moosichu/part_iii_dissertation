%%
%% ACS project dissertation template.
%%
%% Currently designed for printing two-sided, but if you prefer to
%% print single-sided just remove ",twoside,openright" from the
%% \documentclass[] line below.
%%
%%
%%   SMH, May 2010.


\documentclass[a4paper,12pt,twoside,openright]{report}


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Tom M. Read Cutting\xspace}
\def\authorcollege{Downing College\xspace}
\def\authoremail{tr395@cam.ac.uk}
\def\dissertationtitle{Heterogeneous type checking in multi-language CPU-GPU systems}
\def\wordcount{TODO}


\usepackage{color,epsfig,float,inconsolata,graphicx,hyperref,listings,parskip,setspace,tabularx,xspace}
\graphicspath{ {images/} }

\newfloat{lstfloat}{htbp}{lop}
\floatname{lstfloat}{Listing}
\def\lstfloatautorefname{Listing} % needed for hyperref/auroref

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC)
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
% \listoffigures
% \listoftables

\onehalfspacing

%% START OF MAIN TEXT

\chapter{Introduction}
\pagenumbering{arabic}
\setcounter{page}{1}

This chapter provides the motivation for the work this paper - that is the what
the problem is, why it is important and why it has not yet been solved. This is
followed with a brief description of the solutions this paper presents an
overview of the entire document is finally provided.

\section{Terminology}

\begin{itemize}

    \item \textbf{Shader:} A computer program written for the GPU.

    \item \textbf{VRAM:} The RAM a GPU directly accesses. Although computing
    architectures do exist where the CPU and GPU share access to a single pool
    of memory, in most architectures data must be explicitly transferred from
    the CPU's RAM to the GPU's VRAM through a bus.

    \item \textbf{Framerate:} The rate at which a piece of software can render
    a new frame in real-time. Higher is better.

    \item \textbf{FPS:} Frames-per-second, a unit of measurement used to
    quantify the framerate of some software. Due to the refresh-rates of most
    consumer displays, 30FPS and 60FPS are common framerate targets.

\end{itemize}

\section{Motivation}

I introduce how a slow-down in ``Moore's Law'' has led to GPUs becoming
increasingly relevant as more industries have turned to using them due to the
the increased floating point computing power they provide relative to CPUs.
However, I then explain how despite sizeable number of developers using GPUs,
standards and standard practices are few and far between - with a brief
exploration of how legacy APIs, politics and proprietary technologies have led
to an unfortunate amount of fragmentation and steep learning curves for using
GPUs. This is an important problem to work on due to the benefits solutions
could provide to the wide number of developers programming for GPUs.

As a result of the recent slow-down in ``Moore's Law'' \cite{MooreLawSlowdown},
Graphical Processing Units (GPUs) have provided significant gains in
floating-point computing power relative to CPUs \cite{CPUGPUOverTime}. This has
lead to a growth in the use GPUs for general purpose computations (known as
GPGPU). Whilst GPUs were originally designed for rendering the graphics of
games using a fixed-function pipeline, changes in their design over time have
made them increasingly programmable. These design changes were driven by the
desire of game developers to have increasingly realistic, complex and diverse
graphics in their games. Furthermore, this has allowed GPUs to be used in a
broadening domain of applications, including machine learning \cite{TODO},
scientific computing \cite{TODO}, and bitcoin mining \cite{TODO}. Section
\ref{sec:history_gpu} provides more details on this.

However despite this growth, the toolchains used to interact with GPUs still
suffer from many of the problems they did when originally used by graphics
programmers in the early-to-mid 2000s. A large root-cause of these problems is
the fact that the programs written for GPUs (known as \textit{shaders}) have to
be developed in a separate environment. Therefore although data is shared
between the CPU and GPU via a bus, the programmer has to manually ensure that
the data structures used to encode that data is consistent between the programs
written for the GPU and CPU.

\begin{lstfloat}
\begin{lstlisting}[language=C]
// C# struct definition
public struct WaveParticle
{
    public Vector2 origin;
    public Vector2 velocity;
    public float amplitude;
    public float dispersionAngle;
    public int startingFrame;
}
\end{lstlisting}
\begin{lstlisting}[language=C]
//HLSL struct definition
struct WaveParticle {
    float2 origin;
    float2 velocity;
    float amplitude;
    float dispersionAngle;
    int startingFrame;
};
\end{lstlisting}
\label{lst:c_sharp_hlsl_struct_comparison}
\caption{The same datastructure defined separately in C$^\sharp$ and HLSL.}
\end{lstfloat}

Listing \ref{lst:c_sharp_hlsl_struct_comparison} demonstrates a simple example
of this kind of issue, extraced from a simple GPU-accelerated wave simulator
\cite{WaveParticlesGPU}. In this example, units of distortion on the surface of
a liquid are represented using a datastructure known as a \textit{Wave
Particle} \cite{WaveParticlesOriginalPaper}. The CPU handles in-world physics
which result in these particles being generated. However, the GPU is used to
simulate the particles themselves and additionally calculates the shape of the
resulting surface they represent before rendering the results as shown in
Figure \ref{fig:waveparticles_example}. In this case, C$^\sharp$ was the
language used to write code for the CPU, and HLSL was the language used to
write shaders. Therefore, even though the same datastructure is shared, it has
to be defined in both languages. If these definitions do not agree with each
other, there are no in-built mechanisms to catch the errors this causes, at
run-time or otherwise. The outcome of such a mismatch would simply be the
undefined runtime behaviour. Section \ref{sec:api_challanges} fleshes out how
in detail how the APIs used to write programs for GPUs work, and demonstrates
other examples of how errors such as these can occur.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{waveparticles_example}
\caption{The modern 3D graphics card pipeline.}
\label{fig:waveparticles_example}
\end{figure}

There has been research into pushing forward the state-of-the-art in targeting
more programmer-friendly ways. However, as covered in Section
\ref{sec:related_work}, much of the research has either been domain-specific
or provided abstractions which have an unacceptable performance overhead for
most use-cases involving GPUs. (TODO: flesh out).

Developing modern systems which can target heterogeneous platforms in more
user-friendly ways, they sacrifice the control that traditional pipelines
offer.

\section{These Solutions}

TODO


\subsection{Desired Outcome}

TODO


\subsection{What was done}

TODO

I created two systems for type-checking programs accross language boundaries in
CPU-GPU systems. The first is a pre-processing system for C and GLSL that
operates on annotated sections of code. The second is a proof-of-concept pair
of languages with the features provided by the pre-processing system baked-into
the type system at the language level.


TODO: Flesh out.

\section{Overview}

% This is the introduction where you should introduce your work.  In
% general the thing to aim for here is to describe a little bit of the
% context for your work --- why did you do it (motivation), what was the
% hoped-for outcome (aims) --- as well as trying to give a brief
% overview of what you actually did.

% It's often useful to bring forward some ``highlights'' into
% this chapter (e.g.\ some particularly compelling results, or
% a particularly interesting finding).

% It's also traditional to give an outline of the rest of the
% document, although without care this can appear formulaic
% and tedious. Your call.

TODO: Give overview of paper.

\section{Compelling Results}

TODO: Give compelling results.

\chapter{Technical Background}

% A more extensive coverage of what's required to understand your
% work. In general you should assume the reader has a good undergraduate
% degree in computer science, but is not necessarily an expert in
% the particular area you've been working on. Hence this chapter
% may need to summarize some ``text book'' material.

% This is not something you'd normally require in an academic paper,
% and it may not be appropriate for your particular circumstances.
% Indeed, in some cases it's possible to cover all of the ``background''
% material either in the introduction or at appropriate places in
% the rest of the dissertation.

% This chapter covers relevant (and typically, recent) research
% which you build upon (or improve upon). There are two complementary
% goals for this chapter:
% \begin{enumerate}
%   \item to show that you know and understand the state of the art; and
%   \item to put your work in context
% \end{enumerate}

% Ideally you can tackle both together by providing a critique of
% related work, and describing what is insufficient (and how you do
% better!)

% The related work chapter should usually come either near the front or
% near the back of the dissertation. The advantage of the former is that
% you get to build the argument for why your work is important before
% presenting your solution(s) in later chapters; the advantage of the
% latter is that don't have to forward reference to your solution too
% much. The correct choice will depend on what you're writing up, and
% your own personal preference.

This chapter provides extensive coverage of the relevant history of graphics
hardware and how it developed over time to become useful in many fields beyond
real-time rendering in video games. Following that, a breakdown of graphics
APIs is provided, to give both the context for the problem this paper aims to
tackle and the underlying technology the solutions depend upon. Then, the
difficulties and issues with programming for GPUs is summarised from the
contents of this chapter with a brief explanation of which ones the solutions
presented in this paper aim to tackle and which ones they do not. The chapter
finishes of with an overview of related research in this area, demonstrating
both were they succeed and how they fail to tackle the specific problems that
are solved here.

\section{A (brief) History of GPUs}

\label{sec:history_gpu}

Graphics Processing Units (GPUs) were originally fixed-function hardware
accelerators for 3D rendering aimed at hobbyist gamers who desired hardware to
play games with the most complex graphics possible \cite{TODO}. GPUs achieved
levels of fidelity that were otherwise unachievable by being focused on
optimising the \textit{rasterisation} step of 3D graphics rendering in
hardware. This allowed games using GPUs to display much higher levels of detail
(with higher framerates) compared to those using CPUs for rendering (known as
\textit{software rendering}). An early example of this was the video game Quake
and its update GLQuake. Whilst the former used the CPU for software rendering,
the latter supported GPUs through the use of the OpenGL API, allowing for
higher framerates, higher resolutions, improved texture filtering and
additional effects \cite{GLQuake}.

With time, developers wanted increasing artistic control over how video games
were rendered. Therefore, graphics cards stopped being fixed-function hardware
accelerators and the \textit{shader model} was created.

This gave graphics programmers some control over how computer graphics were
rendered. Although initially simple, as the desire for flexibility over these
systems increased, the capabilities of graphics cards themselves did so as
well, reaching a point where they are now essentially highly-parallel
general-purpose computation machines. A lot of the early (and current)
development of GPUs has been driven by a desire to increase the capabilities
they offer to video games, allowing them to drive not just traditional
rendering, but also physics \cite{TODO}, procedural world generation
\cite{TODO}, post-processing effects \cite{TODO} and alternative types of
rendering including ray-tracing \cite{TODO}.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{TODO}
\caption{The modern 3D graphics card pipeline.}
\label{fig:graphics_pipeline}
\end{figure}

However, this increase in flexibility has allowed GPUs be used in increasingly
general domains, including scientific computing \cite{TODO}, crypto-currency
mining \cite{TODO}, video-processing \cite{TODO} and artificial intelligence
\cite{TODO}. To the point where the hobbyists the cards were originally
designed for are being priced out of the market \cite{TODO}.

\section{The Challenges with the APIs}

\label{sec:api_challanges}

This section gives an overview of the general challenges programmers face when
using graphics APIs. Firstly, the context and history of graphics APIs are
described, with a focus on OpenGL and Vulkan. Subsequently, the general
workflow of writing programs for GPUs is described, before finally the
individual problems that type heterogeneous type safety seeks to address are
identified.

Programmers interact with GPUs using APIs, however, as the development of and
growth of GPUs in computing has been relatively organic and ad-hoc, these APIs
themselves have many legacy components and can be difficult to work with.

To understand the challenges of working GPUs, one must first understand the
current workflow of GPUs and how that workflow has developed over time.

The best point of comparison is the CPU, and programming for the CPU. When
programming for the CPU, programmers often have access to a plethora of
programming languages which are suited to different needs and are capable of
targeting a wide range of backends. Furthermore, the instruction sets of CPUs
are published and well-documented, allowing programmers to write applications
for them directly - even allowing them to write their own compiler for them if
they so desire. Finally, in the world of desktop computing, x86 is the de-facto
standard architecture, massively increasing the portability of programs which
target desktop PCs without the need for hardware abstractions which could come
with performance penalties.

The workflow of the GPU is very different.

\subsection{OpenGL}

Although GPUs do not have a standard ISA, open standards for GPU computing have
been developed and maintained by the Khronos Group \cite{TODO}, which was
founded in 2000 by a group companies for this purpose. OpenGL is the most
widely used standard graphics API that they maintain, however, the API has a
history dating back to the early 1990's \cite{TODO}, with control of the
standard being passed from Silicon Graphics in 2006 \cite{TODO}. For a long
time the OpenGL family of graphics APIs were the only cross-platform family of
graphics APIs, with OpenGL ES, a related API, being used for mobile and
embedded systems \cite{TODO}.

Despite OpenGL being an open standard with a differently-flavoured API for
non-desktop systems, portability and development using the API is difficult for
several reasons. The focus of this is on the language-aspects of graphics
programming.

The largest competitor to OpenGL has been Direct3D by Microsoft, and is an
alternative graphics API for Windows computers \cite{TODO}. Other platforms may
have their own proprietary graphics APIs, such a Metal for Apple devices
\cite{TODO}, and the various APIs that gaming consoles provide \cite{TODO}.
Although each of these platforms have their differences, the problems being
tackled can be generalised to all of them. Therefore, this paper will purely
focus on the OpenGL family of graphics APIs.

\subsection{Vulkan}

TODO:

\subsection{Graphics workflow and pipeline}

GPUs are highly parallel compute machines capable of running programs called
\textit{shaders}. However, unlike CPU programs, where a programmer will simply
start writing code in a \texttt{main} function which can be straightforwardly
compiled and executed, shaders require more setup and boilerplate. Typically,
shaders complement programs designed for the CPU, with the traditional example
being a video game. In this case, the core components of a game (such as logic,
animation, scene-setup, input handling) will be handled by the CPU which can
then offload certain computations to the GPU (such as graphics and physics).
The programmer does this by using graphics APIs to initialise the graphics
pipeline to the desired state for a particular computation (setting up buffers,
loading data onto the GPU, initialising the pipeline, reserving resources,
etc.). Following this, those APIs are used to direct the drivers to load
\textit{shader code} onto the GPU. Finally, the shaders are executed for the
desired results.

Although laborious, this workflow allows programmers to use the resources of
GPUs fairly efficiently. However, it is not without issues. The one which this
paper seeks to tackle is down to the fact that \textit{shaders} and CPU code
are written in completely different programming languages.

List to cover:

 - standard has a lot of legacy and issues:
    - different workflows and APIs for different applications
    - non-standard implementations of the standard, with vendor-specific extenions
    and other propietary technologies.
    - standard changes depending on whether targeting desktop, mobile or
    embedded systems
    - must interact with Operating systems directly, such as using their windowing
    system to create a \textit{context}. This reduces portabililty.
    - Langauges are compiled at run-time, with different shader-models
    - Companie wil partner with different vendors
    - Examples


\textit{Issues Summary}

TODO;

\begin{lstfloat}
\begin{lstlisting}[language=C]
const float fixedDeltaTime;
const int currentFrame;
const float particleSpeed;
float2 getPosition(int startingFrame, float2 velocity, float2 origin) {
    float t = (fixedDeltaTime * (float)(currentFrame - startingFrame));
    return origin + (t * particleSpeed * velocity);
}

const int horiRes;
const int vertRes;
const float planeWidth;
const float planeHeight;
StructuredBuffer<WaveParticle> waveParticleBuffer;
RWTexture2D<float4> amplitudeTexture;

///
/// Splat the wave particles to the splatTexture
///
#pragma kernel SplatParticles
[numthreads(THREAD_GROUPS_X, 1, 1)]
void DrawParticles(uint3 id : SV_DispatchThreadID)
{
    WaveParticle particle = waveParticleBuffer[id.x];
    float2 waveParticlePosition = getPosition(
        particle.startingFrame, particle.velocity, particle.origin
    );
    int xPos = (int)round((waveParticlePosition.x / planeWidth) * horiRes);
    int yPos = (int)round((waveParticlePosition.y / planeHeight) * vertRes);
    amplitudeTexture[int2(xPos, yPos)] +=
        float4(0.0, particle.amplitude, 0.0, 0.0);
}
\end{lstlisting}
\label{lst:draw_particles}
\caption{An example of an HLSL computer shader that takes a particle stored in
in a buffer and copies its amplitude to a specific location on a texture.}
\end{lstfloat}

\section{Related Work}

\label{sec:related_work}

TODO:

\chapter{Design}

The heterogeneous type checking aspects of the projects is composed of two
alternative systems. The first is a pre-processing system for C and GLSL that
ensures the enforcement of interfaces between the two languages. The second is
a set of two novel toy languages which natively support such enforcement.

\section{Workflow}

One of the important parts of the system is the implementation of the workflow.

\section{Lexer}

TODO:

\section{Parser}

TODO:

\section{Semantic Analysis}

TODO:

\chapter{Implementation}

% This chapter may be called something else\ldots but in general
% the idea is that you have one (or a few) ``meat'' chapters which
% describe the work you did in technical detail.

The source code for the project is publicly available and open-source
\cite{ProjectSource}. The implementation is formed of two distinct components,
the C-annotation pre-processor and the custom-languages compiler. Although both
are written in C++, Python is also used as a build-system to enable simple
cross-platform builds. The project was developed and tested on both Ubuntu
16.04 and Windows 10 operating systems.


\section{Pre-processor}

TODO:

\section{Compiler}


TODO: reference usage of FNV hash for symbol table. \cite{FNVHash}.






\chapter{Evaluation}

% For any practical projects, you should almost certainly have
% some kind of evaluation, and it's often useful to separate
% this out into its own chapter.

TODO:

\chapter{Conclusion and Further Work}

% As you might imagine: summarizes the dissertation, and draws
% any conclusions. Depending on the length of your work, and
% how well you write, you may not need a summary here.

% You will generally want to draw some conclusions, and point
% to potential future work. \cite{DirectXWorkings}

TODO:

\chapter{Related Work}

TODO: Discuss all related work in the field.

\appendix
\singlespacing

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
