\documentclass[11pt]{article}
\usepackage{a4wide,parskip,times}
\usepackage{cite}
\usepackage{url}

\begin{document}

\centerline{\Large Heterogeneous type checking in multi-language CPU-GPU systems}
\vspace{2em}
\centerline{\Large \emph{A PartIII project proposal}}
\vspace{2em}
\centerline{\large T. M. Read Cutting (\emph{tr395}), Downing College}
\vspace{1em}
\centerline{\large Project Supervisor: Prof A. Mycroft}
\vspace{1em}

\begin{abstract}

Programming for the GPU can be complex, error-prone and hard to manage using
existing tool chains, as programmers are required to write code in different
languages for the GPU and CPU, with little to no runtime or compile-time safety
across the boundaries between them. Various research has been done into
creating and designing unified programming languages which can be compiled to
heterogeneous architectures with systems to allocate load at runtime, handling
parallelisation and vectorisation automatically. These languages greatly
simplify the programming workflow. However, these languages are either domain
specific or have otherwise yet to experience serious uptake in soft real-time
applications due to various factors, including runtime overhead, lack of
low-level control, and other inefficiencies which make them unsuitable for the
domain. The result of this is that existing tool chains have not developed
alongside the existing research which aims to target systems of the future as
opposed to acknowledging the current state of affairs.

This project proposes a pragmatic solution of using a hybrid system composed of
two programming languages which each compile down to their respective
architectures (CPU/GPU), similar to existing workflows. This project
contributes to the field in providing a unified type-checking system across the
two languages in order to eliminate common errors - with the ability to use
type-safe syntactic sugar that compiles down to the boilerplate code that
handles API calls across the CPU/GPU boundary.

\end{abstract}

\section{Introduction, approach and outcomes (500 words)}

Increasing amounts of general computation is being offloaded to GPUs in soft
real-time applications such as games \cite{GPGPUTechniques2012}. Programs which
run on GPUs are called shaders, and running them has historically required
using high-level APIs like OpenGL and DirectX to manually pass shader
source-code (GLSL and HLSL respectively) to GPU drivers which then compile and
run them at runtime \cite{OpenGLWorkings} \cite{DirectXWorkings}. Although
modern graphics APIs like Vulkan \cite{Vulkan} operate in a similar manner,
SPIR-V, a new intermediate representation (IR) language is used to pass
pre-compiled shaders instead \cite{SPIR-V}.

However, despite data structures being passed back-and-forth between the CPU and
the GPU, the type and error checking between the two platforms and their
respective languages has historically been non-existent. Furthermore, the APIs
require extensive boilerplate in order to set-up shader invocations, another
surface for errors.

Various projects and tools have developed which aim to manage these
complications at different levels. One approach is to develop domain specific
languages (DSLs) with high-levels of parallelism that allow them to be
automatically compiled for a wide variety of heterogeneous architectures
\cite{DSL1} \cite{DSL2} \cite{Theano2016}.

However, these systems are unsuitable for real-time applications which require
general purpose computation and fine-grained control of resource usage in order
to achieve deterministic and consistent performance - meaning that they have not
seen much uptake beyond scientific computing \cite{Theano2016}.

Another approach is take existing languages and extend them top-down with
support for heterogeneous architectures via annotated code, taken by C++ AMP
\cite{CAMP}, JCUDA \cite{JCUDA2009}, and more \cite{SYCL} \cite{HCC}
\cite{Theano2016} \cite{CParallel}. However, so far these have suffered from
the same inability to offer the user fine-grained control that DSLs do, and the
top-down approach of making existing general-purpose languages semi-compatible
with GPUs makes them awkward to work with, meaning they have been unsuccessful
in gaining traction in industry \cite{CAMPFail1} \cite{CAMPFail2}.

The third approach that has been taken is to design a single general-purpose
language from the bottom-up with compile-time and runtime-systems built in to
allow for automatic resource management and workload distribution across
heterogeneous architectures \cite{Lime2012} \cite{Lime2010}. Although these
systems may represent the future of heterogeneous computing, they still have a
long way to go before seeing serious uptake.

My project will be to take a bottom-up approach in designing and implementing
two langauges, one for the CPU and one for the GPU - allowing for the
context-aware programming and fine-grained control that existing bottom-up or
top-down single-language systems do not provide. Furthermore, the bottom-up
design will allow for a unified type-system to allow for compile-time checking
of common errors which can frustrate current GPU programmers. Finally,
syntactic sugar for the explicit control of boilerplate generation at the
language level can help reduce another class of errors as well.

By the end I will have produced a language design and associated compiler that
can be used to compile the language, with suitable components being compiled
for a CPU and GPU backend.

My evaluation will consist of demonstrating which problems have been solved,
showing equivalent C/GLSL programs where those problems can be easily be
introduced, and showing how the new languages compile without them present
whilst still having the similar runtime performance. As the focus of this is
not on compile-time optimisations, the testing will be performed with compiler
optimisations disabled.

\section{Workplan (500 words)}

Although the goal is to take a bottom-up approach, the aim is to do so
iteratively, by targetting individual components in the existing workflow and
designing language features which make them less cumbersome. A proof-of-concept
boiler-plate generation system can be implemented as pre-processing step of a
GLSL and C setup using OpenGL API calls.

However, because the desired result is the implementation of two new
programming languages, the scope of the project needs to be limited with the
focus being on researching, evaluating, refining and testing the type-checking
and boiler-plate generating features of the design. Therefore I have decided to
write small-scale representative programs so I can evaluate the ideas
presented without being distracted by "feature-completeness".

These programs will initially be written in a combination of GLSL and C to
allow for the iterative approach described above. They will also provide a
reference target of what a new implementation should ideally compile-down to.

Firstly, a boilerplate generation system will be implemented for GLSL and C,
using modified versions of these programs to take advantage of the system for
testing. The goal of this system is to generate the required OpenGL API calls
in the C program that are needed in order to invoke compute shaders written in
GLSL. This system will not include any safety features or compile time checks.
This boilerplate generation system will also help inform syntactical and
semantic choices for the new languages.

I will then create a transpiler that can take simple programs written in two
languages designed from the bottom-up to have compatible type systems - which
transpiles the CPU-specific code to C and GPU-specific code to GLSL. This
transpiler can also take advantage of the boilerplate generation features
described in the previously.

The next stage will be to extend the transpiler generation system to statically
analyse the programs to ensure type safety across architecture boundaries and
that correct initialisation of variables is occuring - a common source of
errors. This decision to transpile will also more easily allow for the
extension of having the new languages to call into existing code and libraries
written in C, and similarly allow C to call into it.

Finally the system will be evaluated, as I will have multiple versions of the
same programs on hand - in C/GLSL with boilerplate, in C/GLSL without
boilerplate and in the new languages. These can be used as point of comparison
and the features available in all systems can be analysed.

\bibliography{references}
\bibliographystyle{ieeetr}

\newpage
\appendix

\section{Time Table}

Counting from the 1st of December to the aimed submission date of the 27th of
November there are 25 weeks. So I will plan for 24 weeks of work, including a
grace week in case I fall behind.

\subsection{Weeks 1-2 (20 hours)}

Write sample programs with an OpenGL backend in C/GLSL that can be used to
demonstrate the common issues a new language design could solve. It is
important that these programs use a subset of the features available in C/GLSL
to allow them to be more easily be rewritten in new languages, and to help
limit the features those languages will need to implement. As the goal of the
language is not to re-implement existing languages, but demonstrate how a
language could be designed to solve these common problems. One of the programs
can be for the CPU only for testing purposes.

\subsection{Weeks 3-4 (25 hours)}

Implement the boilerplate generation system described in the Workplan.

\subsection{Weeks 5-6 (30 hours)}

'Port' the sample programs to what they would ideally look like in the
front-end of a new languages. Send these off for feedback from the project
supervisor. Start designing a grammar for the language for parsing.

\subsection{Weeks 7-8 (20 hours)}

Implement a parser for the languages and construct an AST of the simplest
sample programs.

\subsection{Weeks 9-10 (20 hours)}

Compile the AST down to C/GLSL and then get that system working.

\subsection{Weeks 11-12 (20 hours)}

Start the implementation of a type-checker that operates on the AST.

\subsection{Weeks 13-14 (30 hours)}

Complete the implementation of a type-checker that operates on the AST and
demonstrate it can catch the errors the can be easily demonstrated to occur.

\subsection{Weeks 15-16 (40 hours)}

Expand the system to compile more complex sample programs, including those that
interoperate with C. Demonstrate the the sample programs can be compiled and
run in an equivalent manner to their C counterparts.

\subsection{Weeks 17-18 (40 hours)}

Perform a formal evaluation of the system.

\subsection{Weeks 19-20 (40 hours)}

Write the first draft of the dissertation. Send it to my project supervisor for
feedback. Work on developing the software further in any and use this week to
catch up.

\subsection{Weeks 21-22 (40 hours)}

Once the first draft has been returned with feedback, write second draft of the
dissertation.

Flesh-out and demonstrate more ideas. Use these two weeks to investigate
further directions this could go and implement any possible extensions
(including the ability to call out to exiting C code). Polish is the main focus
here.

\subsection{Weeks 23-24 (40 hours)}

Write final draft of the dissertation. Send it to my project supervisor for
feedback. The main focus of this week is on polish and bugfixes. Also focus on
making the work reproducible and presentable for others to use and test.

% \section{Example of boilerplate elimination and error checking}

% TODO:




\end{document}
